\documentclass[bachelor,english]{hgbthesis}

\begin{document}

\title{Hybrid Threads for the Parrot Virtual Machine}

\author{Stefan Seifert}
\studiengang{Software Engineering}
\studienort{Hagenberg}
\abgabemonat{Februar}
\abgabejahr{2012}

\nummer{1010307037-A}
\gegenstand{SWE}
\semester{Wintersemester 2012}
\betreuer{Dr. Heinz Dobler}

\frontmatter
\maketitle
\tableofcontents

\chapter{Thanks (1)}

Andrew "whiteknight" Whitworth for laying the foundations for my work, being of tremendous help at all stages of the project and for fixing some of my bugs.

Nat "Chandon" Tuck for implementing green thread basics on which my work is based.

Christoph "cotto" Otto for bringing me into the Parrot project.

Brian "benabik" Gernhardt for lurking in the IRC channel and at least trying to help with my many questions.

\chapter{Abstract (1)}

\begin{german}
\chapter{Kurzfassung (1)}
\end{german}

\mainmatter

\chapter{Introduction and Motivation (3)}

On July 19th 2000, the Perl 6 design process was announced. Perl 5 had been a very flexible and widely used programming language but had started to show its age and suffered from early design decisions. The Perl interpreter is written in C and has accumulated a lot of cruft over the years. The general consensus among the core developers was that the code had reached a state where maintenance was approaching impossibility. [http://use.perl.org/~masak/journal/40451]. An attempt to reimplement these internals had failed but led to the decision that the interpreter for a Perl 6 language should be developed independently of the needs of Perl 5. Since the Perl 6 syntax was very much in flux (and parts of it still are) the designers of these new internals tried to work very independently of any syntax related questions. [http://www.developer.com/lang/perl/article.php/10940\_3076571\_3/Perl-6-and-the-Parrot-Project.htm]. Taking up the name born in an April Fool's Day joke announcing the merging of the Perl and Python programming languages, these new internals were called Parrot. [http://www.perl.com/pub/2001/04/01/parrot.htm]

Parrot evolved from being just the interpreter for the new version of Perl to being a language independent virtual machine providing features like garbage collection, exception handling and dynamic typing. At the time when the Parrot project started, the Java and .NET virtual machines were widely used, but both targeted statically typed languages. Parrot thus filled a quickly growing niche.

The Perl 6 design process began with asking the Perl users for what they were expecting from the new version of the language. The very first feature that got asked for was well integrated multi-threading support [http://dev.perl.org/perl6/rfc/1.html]. Perl 5 had two different implementations of thread support. In the first model, called 5005threads, data was shared by default and shared access to data had to be explicitely synchronized. This was similiar to the models used by languages such as C or Java. The implementation however suffered from data corruption and crashes and thus was not recommended for production use [http://search.cpan.org/~nwclark/perl-5.8.8/lib/Thread.pm]. Perl 5.6 introduced the newer model called ithreads, mostly as a way to emulate fork() on Win32 platforms. Perl 5.8 exposed this API to the user of the programming language. In this new model, all data is copied to each thread and afterwards thread local. Data must be explicitely shared between threads. In other words, in Perl threads are not lightweight at all. They have severe impact on memory usage, writes to shared data are expensive and still not all features of the language are usable in threaded programs.

Being born at a time when Perl 6 still looked much more similiar to Perl 5 than it does nowadays, Parrot's threading support initially was very close to Perl's ithreads model. Previous attempts to change this into the more conventional model of data shared by default or implementing new technologies like Software Transactional Memory failed. For example Parrot has never supported running multiple threads and having garbage collection at the same time.

\section{Why is multi-threading support so important?}

In the year 2005 development of faster CPUs shifted from increased speed of a single core to adding more cores. Modern processors contain up to 12 cores with even mobile phones having up to four. To utilize a modern CPU's power, code needs to be run in parallel. In UNIX (and thus Perl) tradition, this is accomplished using multiple processes which indeed is a good solution for many use cases. For many others like Perl 6's auto threading of hyper operators, the cost of process setup and communication would be prohibitively high except for very large data sets.

\section{Why is it so difficult to implement multi-threading support in Perl or Parrot?}

Low level programming languages like C provide only the bare necessities, leaving the responsibility for preventing data corruption entirely to the user. A high level language like Perl 6 on the other hand offers complex and compund data types, handles garbage collection and a very dynamic object system. Even seeminlgy simple things like a method call can become very complex sequences. In a statically typed programming language the definition of a class is immutable. Thus calling a method on an object contains just the steps of determining the object's class, fetching the required method from this class and calling it. Calling the same method again may then even omit the first two steps since their results cannot change.

In a dynamic language, the object may change its class at runtime. The inheritance hierarchy of the class may be changed by adding or removing parent classes. Methods may be added to or removed from classes (or objects) at runtime and even the way to find a method of a class may change. So a simple method call may result in the following steps:
%
\begin{itemize}
\item determining the class of the object
\item determining the method resolution method of the class
\item finding the actual method to call
\item calling the method
\end{itemize}
%
These steps have to be repeated for every following method call, because their results may change any time. In a threaded environment, a thread running in parallel may change the underlying data and meta data in between those sequences and even between those steps. As a consequence, this meta data has to be protected from corruption introducing the need for many locks in a very performance critical area.

While there are multi threaded garbage collection schemes, their implementation has not yet been attempted in Parrot.

Many interpreters for dynamic languages like Python or Ruby handle this problem by using a global interpreter lock to effectively serialize all operations. This is a proven and reliable way but again leaves much of the hardware's potential unused.

\section{Current status}

During these years of back and forth and failed attempts of adding threading support to Parrot, the Perl 6 specification evolved to a point where the largest parts of the language were covered and its features implemented in the compilers. The lack of concurrency primitives in Parrot however prevents any progress in the area of concurrency support.

Before the work on this paper, Parrot did not have any threading support at all. The previous, defunct implementation had been removed.

This paper suggests a new approach based on a hybrid threading system. So called green threads are used to simplify the implementation of a nearly lock free multi threading implementation. This approach is based on a design by Andrew Whitworth and Nat Tuck.

\chapter{Concurrency in other Programming Platforms (5)}

This chapter is talking about programming platforms. A platform is seen as a combination of a programming language and a runtime. For example for the Python programming language there are multiple runtimes with different implementations of threading support.

\section{Java}
\section{Python}
\section{Erlang}

\chapter{Parrot (4)}

Parrot consists of the virtual machine (also called interpreter), and various tools to facilitate the implementation of programming languages on top of the Parrot VM (the Parrot Compiler Toolkit). In this paper, we concentrate on the virtual machine itself. The interpreter itself is written in C. Example code and testcases are written in PIR (Parrot Intermediate Representation) a high level assembly language which abstracts away register allocations and function calling conventions.

Contrary to other widely used virtual machines like the JVM or the CLR which are stack based, Parrot mirrors contemporary hardware CPUs more closely by being register based. A stack based virtual machine usually fetches the operands of an operation from the top of a stack and puts the result back on top. Thus the operands chosen implicitely by ordering of the operations allowing the opcodes to be quite small. In a register based VM on the other hand each operation has to specify the operands explicitely. Compilers for stack machines are simpler because they do not have to care about register allocations and code is independent of prior or subsequent code. [http://static.usenix.org/events/vee05/full\_papers/p153-yunhe.pdf] The rationale behind giving up the simplicity of a stack based implementation is the hope of simplifying just in time compilation and improved performance of nested function and method calls.

The current design uses four sets of registers with each and unlimited number of usable registers. The four sets are:
%
\begin{itemize}
\item integer
\item floating point
\item string
\item polymorphic container (PMC)
\end{itemize}

The first three should be self explanatory. Strings in Parrot are a low level type with the interpreter handling all memory allocation issues and Unicode encoding. String values themselves are immutable.

\section{PMCs}
\label{sec:PMCs}

PMCs are containers for all higher level types such as objects, arrays, hash tables or code. Thus they are very similar to Python's PythonObject types. PMCs are defined by C structs and are fully garbage collected. Their definition looks like:
\begin{CCode}
struct PMC {
    Parrot_UInt    flags;
    VTABLE         *vtable;             /* Pointer to vtable. */
    DPOINTER       *data;               /* Pointer to attribute structure. */
    PMC            *_metadata;          /* Pointer to metadata PMC. */
};
\end{CCode}
In short it contains a pointer to a type specific data structure and some meta data. The vtable is where the type's behaviour is defined. It contains a long list of function pointers forming Parrot's unified type interface. This interface is a union of numeric, string, array, hash and object like behaviours. For example the  \textit{get\_integer} function returns an integer value for the data type. For a simple \textit{int} it's the contained value. For an array it may be the number of elements. The \textit{find\_method} function makes user defined methods of objects possible.

In this way, a language implementor can define the basic types of the language and available operations on them. For each vtable entry, there is a corresponding op code in Parrot's bytecode. Thus an \textit{inc \$P0} instruction is calling the \textit{increment} vtable function of the PMC contained in the \textit{\$P0} register.

PMCs are implemented in .pmc files with method bodies written in C. These files get preprocessed to plain C before compliation.

\section{ParrotInterpreter}

The interpreter itself is represented by a C struct called \textit{parrot\_interp\_t}. This structure contains pointers to the garbage collector's runtime data, the loaded types, vtables, the runloop, the current continuation and other global data. A pointer to this structure is passed to almost every function as the first parameter.

\section{Continuation passing}

Control flow is modeled in Parrot using continuation passing. A continuation is a data structure containing the a state of a program at a given point in its execution. It contains all information which is needed to continue a program in a certain state, e.g. a call stack, the instruction pointer and contents of local variables. ``Calling'' a continuation means restoring the state encapsulated in the continuation.

When a function is called, instead of pushing all this information on the stack, the function is given a return continuation as part of its parameters. Returning from a function means calling the return continuation with possible return values stored in the registers where the calling code is expecting them. Continuation passing makes things like tail call optimization \footnote{When as the last statement of a function another function is called and its value returned unchanged, the outer function may just pass on its return continuation thus saving the need to create a new continuation and one step on returning from the nested function} very simple and as we will see later will be a very important piece in implementing green threads.

\section{Runloops}
\label{sec:Runloops}

A runloop is in principle the most inner loop executing bytecode in Parrot. It is also a data structure containing some information needed to support exception handling. When some operation in Parrot bytecode is calling a C function and this C function in turn is again executing Parrot bytecode, a nested runloop is started. Examples for such situations include calling a library function with a callback as parameter and exceptions thrown inside Parrot's C code which call a previously defined exception handler in user code.

\section{Exception handling}

Before entering a runloop, the \textit{setjmp} C function is used to save the current stack position and register contents to a data structure stored in the runloop meta data. This is effectively creating something resembling a continuation at C level. When an exception is created within the interpreter, the runloop stack is searched for the runloop containing a suitable exception handler. \textit{longjmp} is then used to unwind the call stack up to the point where setjmp was called and the call environment restored. While having great similarities with continuations, this mechanism is more limited. It only allows to jump back to a point higher in the call stack.

\section{Garbage collector}

Parrot supports different garbage collector implementations which can be selected at interpreter startup. Currently there are four existing implementations of different algorithms:
\begin{itemize}
\item Inf: a GC for debugging purposes which never collects any garbage
\item MS: a basic mark and sweep implementation
\item MS2: a non-recursive mark and sweep implementation
\item GMS: a generational, non-compacting, mark and sweep GC
\end{itemize}
with GMS being the default.

A mark and sweep garbage collector operates in two phases. In the mark phase, starting from a known root set of objects, the GC follows pointers down the object tree, marking each encountered object as alive. In the sweep phase, all objects which are not alive are destroyed and the live flags reset.

In a process with many objects, having to traverse the whole tree may take a considerable amount of time. To mitigate this, a generational garbage collector extends this algorithm by assuming that the longer an object has lived, the lower the chances are that it will become unused. So the objects are partitioned into different generations. The youngest generation would always be traversed while the older generations would be handled much less frequently or even never more at all.

\section{Historical development (1)}

\chapter{Green threads (3)}

Green threads are one way to model concurrent control flows in a program. To get a better understanding of what they are and how they work, we will first discuss the possible options.

\section{Coroutines}

Coroutines are functions which retain their state between calls. Instead of returning, they yield control back to the calling function, possibly with an intermediate result returned. A very simple example in Python could look like:
\begin{GenericCode}
def counter():
    for i in range(0, 100):
	yield i
\end{GenericCode}
This function would return one integer for every call, counting from 0 to 100. An example usage would look like:
\begin{GenericCode}
x = counter()
print x
x = counter()
print x
\end{GenericCode}
This example would print the numbers 0 and 1. As we can see, for the two functions to run in parallel, they have to cooperate. One by calling the other repeatedly and the callee by yielding control back to the caller.

\section{Operating system threads}

Operating system threads are like multiple processes running at the same time but share their memory. The operating system is responsible for giving each of these threads CPU time to run. Operating system threads are the only of these options where more than one thread may be executed by the CPU(s) at the same time if the hardware permits.

\section {Green threads}

"Green threads" or "lightweight threads" are threads which are managed by the virtual machine instead of by the operating system. These threads only run pseudo parallel. The virtual machine contains a scheduler and support for preempting running tasks.
Preemption means to suspend a task regardless of what it's currently doing and probably resuming it later on.
This is an implementation of the many-to-one threading model very similiar to what an operating system running on a system with a single CPU core does.
%
Advantages of green threads are:
%
\begin{itemize}
\item They allow pseudo concurrent processing without endangering the interpreter's internal consistency.
\item Green threads are very light weight with low memory overhead and close to zero creation time.
\item They do not depend on OS threading support
\item The interpreter controls the point at which a green thread is preempted.
\item The interpreter controls the exact scheduling policy and may allow the user to influence it or even take over completely.
\item Garbage collection can be implemented like in a single threaded process.
\item Critical sections may simply be protected by disabling the scheduler until the code is clear of the section.
\end{itemize}
%
Disadvantages include:
%
\begin{itemize}
\item They do not allow more than one CPU core to be used for computations.
\item Blocking calls like I/O block the whole interpreter including other green threads.
\item The interpreter has to contain logic and timers to control green threads.
\end{itemize}

Green threads differ from coroutines in that the interpreter decides when a running task is to be preempted while a coroutine depends on manual yield calls.

Let's look at a simple example to explain why concurrent processing could endanger the interpreter's internal consistency. The basic problem is concurrent writes to shared data. Assume we have an implementation of an array class consisting of the field holding the data and the number of contained elements in a seperate member variable:
\begin{CCode}
pmclass ResizableIntegerArray auto_attrs provides array {
    ATTR INTVAL   size;      /* number of INTVALs stored in this array */
    ATTR INTVAL * int_array; /* INTVALs are stored here */
\end{CCode}
To append a new value, the array would have to read the current size, write the new value at the position size + 1 and then write the incremented size back into the member variable.
Now if two threads simultainously try to do this, it may happen that both read the same size, write to the same position (with one overwriting the value of the other) and write back the same incremented size. In this case one of the appended values would be lost.

In a more complicated example, the array could have to resize its data buffer to accomodate the new value. It would read the current size, allocate a new buffer, copy the values to the new buffer and then destroying the old one. Again if two threads try to do this simultainously, one of them could still be copying data, while the other is already at the point where it destroys the old buffer. This would lead to the copying thread accessing freed memory.

If we bring garbage collection into the mix, the possibilities for corruption grow even more. At the point where the first thread needs to allocate the new buffer, the garbage collector could decide that it needs to run and clear some unused memory. It would have to traverse the object tree to mark alive objects. Between the mark and the sweep runs, the second thread could change the pointer to the buffer from the old one to the new one. So the old buffer would have been marked alive, while during the sweep run the new buffer would be in its place, but not yet marked alive.

\section{Green threads in Parrot}

Parrot's green threads implementation is based on Nat Tuck's green\_threads branch developed during his Google Summer of Code internship.

In Parrot green threads are called \textit{Task}. Each task is assigned a fixed amount of execution time. On expiry a timer callback sets a flag which is checked for at execution of every branch operation. Since the interpreter's state is well defined at this point, its internal consistency is guaranteed. The same goes for the garbage collector. Since task preemption is only done while executing user level code, the GC can do its work undisturbed and without the need for measures like locking. Since user level code is allowed to disable the scheduler, it can be guaranteed to run undisturbed through critical sections.

The scheduler is implemented as a PMC (Parrot's polymorphic container type). The plan is to allow the user to subclass this PMC thus allowing very fine grained control over the scheduling policy. Features a user could add this way would be for example giving different priorities to tasks or implementing the possibility to suspend and resume a task.

\chapter{Design of Hybrid Threads (3)}
\label{cha:design}

This chapter describes how green threads were used to solve the following problems which occur when trying to implement threading support:
%
\begin{itemize}
\item How to ensure internal interpreter consistency when doing writes to shared data.
\item How to implement critical sections.
\item How to handle garbage collection.
\end{itemize}

In keeping the analogy of the interpreter being a software CPU, multithreading is implemented by having a separate interpreter with its own register set for each thread. When a user starts a new task, the scheduler first looks for an idle thread. If one can be found, the task is scheduled on the thread's interpreter. If none can be found, a new thread with a new interpreter is started. Parrot tries to optimize the number of utilized threads by creating at most one for each CPU core in the system. If more tasks are started than the maximum number of threads, the tasks are distributed evenly among the running interpreters. This is effectively an implementation of the N:M threading model.

\section{Shared data}

As described in the introduction, cross thread writes to shared data may endanger the internal consistency of the interpreter. Traditionally the response to this problem is the use of locks of varying granularity. Fine grained locking allows code to run well parallelized but taking and releasing locks also costs performance. It not only increases the instruction count and memory accesses but it also forces the CPU cores to coordinate and thus communicate. Even a seemingly simple operation like an atomic increment may take two orders of magnitude longer than a normal increment [http://irl.cs.ucla.edu/~yingdi/paperreading/smp\_locking.pdf]. While the gain through being able to utilize multiple CPU cores may offset this cost, it is still impacting the very common case of having only a single thread running.

Too coarse locking on the other hand would reduce scalability and the performance gains through parallel execution by having threads wait for extended periods for locks to become open. In the extreme case of having a global interpreter lock it may even effectively serialize all computations costing much of the benefits of using threads in the first place.

The other problem with locking is the possibility of introducing dead locks. For example, two functions F1 and F2 both use two resources A and B protected by locks. If F1 first locks A and then tries to lock B while F2 has already locked B and is now trying to lock A, the program would come to a halt. Both functions would be left waiting for the other to unlock the resource which will never happen. With fine grained locking the possibilities for such bugs grow quickly. At the same time it's easy to miss a case where a lock would be appropriate leading to difficult to diagnose corruption bugs.

The solution for these problems implemented for this paper is to side step them altogether by disallowing write access to shared data. The programmer (or in most cases the compiler) is obliged to declare a list of all shared variables before a newly created task is started. The interpreter would then create proxy objects for these variables which the task can use to access the data. These proxies contain references to the original objects. They use these references to forward all reading vtable functions to the originals. Write access on the other hand would lead to a runtime error.

In other words all data is owned by the thread creating it and only the owner may write to it. Other threads have only read access.

For threads to be able to communicate with their creators and other threads, they still need to write to shared data. This is where green threads come into play. Since green threads are very light weight, it is feasible for a thread to create a task just for updating a variable. This task would be scheduled on the interpreter owning this variable. To reduce latency, the task is flagged to run immediately. The data owning interpreter would preempt the currently running task and process the new write task. Put another way, the data owning interpreter is simply told what to write to its variables, so other threads don't have to.

\section{Critical Sections}

In this scheme critical sections can simply be implemented by disabling preemption till the code is clear of the section. With other threads not being allowed to write to the data and the current task running uninterrupted it it guaranteed to complete without the data being changed from outside.

\section{Garbage Collection}

A garbage collector has to traverse and process the entire tree of objects in memory. If during this traversal another thread is changing this tree by creating new objects, moving them around in the tree or removing them, the garbage collector's data would be compromised. For example it could happen that the GC does not mark referenced objects alive because they were added to parents which already have been processed.

In previous attempts to implement threading support in Parrot, the answer to this problem was to disable the garbage collector while multiple threads are active. Other VMs solve this problem by suspending all threads while the GC is running. While multi threaded garbage collection algorithms exist, their implementation would have been to complex and brittle for this paper [http://doc.cat-v.org/inferno/concurrent\_gc/].

Since cross threaded writes are already forbidden and all read access to other thread's data goes through the very narrow channel of proxy objects, forcing a complete separation of the thread's memory domains was only a small step. By having separate memory areas for each interpreter, it became possible to have each interpreter to run its own garbage collector. This way, the known to work single threaded GC implementation could be continued to be used.

Separation of memory domains is a problem for objects which are only referenced from other threads. But since all objects which could be accessed from other threads have to be pushed onto the Task object representing such threads, they can still be referenced from there.

\chapter{Implementation of Hybrid Threads (13)}

\section{The Scheduler (3)}

The scheduler is the place where most of the green thread logic is implemented. It consists of two parts: functions using the prefix \textit{Parrot\_cx} which are located in \textit{src/scheduler.c} and the Scheduler PMC type containing the scheduler's data and public interface.

\textit{Parrot\_cx\_init\_scheduler} is called from \textit{Parrot\_interp\_initialize\_interpreter} whenever a new interpreter is created, e.g. on interpreter startup and whenever a new thread is created. It creates the scheduler PMC and sets up alarm singal handling.

The scheduler is hooked into the system by replacing the call to execute the \textit{main\_sub} by a call to \textit{Parrot\_cx\_begin\_execution}. The latter creates the main task using \textit{main\_sub} as the task's code. This task is then put onto the run queue. The scheduler timer gets enabled and control given to \textit{Parrot\_cx\_outer\_runloop}.

\textit{Parrot\_cx\_outer\_runloop} is the core loop taking tasks from the run queue and executing them. Despite its name, it should not be confused with runloops discussed in section~\ref{sec:Runloops}. \textit{Parrot\_cx\_outer\_runloop} actually consists of two nested loops. The inner loop simply fetches tasks and executes as long as tasks are available. Even when all tasks are finished there may still be alarms pending which upon expiry would trigger new tasks to be scheduled. For this reason there's an outer loop checking for pending alarms and if there are putting the thread to sleep until the next alarm expires.

\textit{Parrot\_cx\_next\_task} contains the code to take the next task from the run queue and executing it. Before calling the task, it checks if there are other tasks still in the queue. Only if other tasks are waiting, task preemption gets enabled. Otherwise the current task would run until it finishes by itself, schedules other tasks or an alarm expires. this is an important optimization reducing the runtime overhead of green threads in the important single tasking case essentially to 0.

To enable task preemption, \textit{Parrot\_cx\_enable\_preemption} sets a flag on the scheduler PMC and uses \textit{Parrot\_cx\_set\_scheduler\_alarm} to set an alarm at a point \textit{PARROT\_TASK\_SWITCH\_QUANTUM} milliseconds in the future.

When an alarm is triggered, Parrot only increments the global \textit{alarm\_serial}. This serial is checked for changes by \textit{Parrot\_alarm\_check} which is called by \textit{Parrot\_cx\_check\_scheduler}. This function in turn is called once for every \textit{branch} op. When the serial is different from the last check or the \textit{SCHEDULER\_wake\_requested} flag is set, \textit{Parrot\_cx\_check\_scheduler} wakes the scheduler by calling \textit{Parrot\_cx\_run\_scheduler}.

Since POSIX alarms can only be delivered to the main thread of a process, \textit{Parrot\_cx\_run\_scheduler} uses \textit{Parrot\_thread\_notify\_threads} to relay alarms to other thread's schedulers. For this purpose every thread has a pipe which \textit{Parrot\_thread\_notify\_threads} writes a dummy byte to. The next step for \textit{Parrot\_cx\_run\_scheduler} is to check for any expired alarms using \textit{Parrot\_cx\_check\_alarms}. An alarm contains a task as callback. On expiry this callback gets scheduled for immediate execution. As alarm signals do not contain any information about their origin, the scheduler does not know if the alarm was scheduled by user code or if it's the scheduler's preemption alarm. \textit{Parrot\_cx\_check\_quantum} is therefore used to check if the current task has used its assigned quantum and if it should be preempted.

Preemption of a task is implemented in \textit{Parrot\_cx\_preempt\_task}. It uses \textit{Parrot\_cx\_stop\_task} to create a continuation at the current point of execution and store it as the task's code. The task itself is then appended at the end of the run queue. The NULL opcode return value is propagated all the way up through the stack back to the \textit{branch} op checking for alarms. The op then recognizes this as the signal to stop processing and to exit the runloop.

The control flow ends up back at \textit{Parrot\_cx\_next\_task} at the point after executing the task at which it returns to \textit{Parrot\_cx\_outer\_runloop}.

The \textit{schedule} op code is used to schedule a new task from user code. It uses \textit{Parrot\_cx\_schedule\_task} which starts new worker threads if needed and possible and pushes the task on the target thread's scheduler's task queue. If the target thread previously was executing only a single task, its preemption has been disabled for optimization as described above. So in this case \textit{Parrot\_cx\_schedule\_task} has to enable preemption to give the new task a chance to run.

\textit{Parrot\_cx\_schedule\_immediate} is used in various places like at alarm expiry for putting a task to the head of the run queue and immediately causing preemption of the currently running task. It does this by setting \textit{SCHEDULER\_wake\_requested} and \textit{SCHEDULER\_resched\_requested} flags the same as when the preemption alarm expires. To be precise this mechanism leads to the current task being preempted at the next \textit{branch} op since this is the place when the mentioned flags will be checked.

Alarms can be registered using \textit{Parrot\_cx\_schedule\_alarm}. It puts the alarm in the appropriate place in the ordered alarm list and uses \textit{Parrot\_alarm\_set} which sets the actual alarm but only if there's not another alarm already set for an earlier time since there can only be one POSIX alarm pending at any time.

\textit{Parrot\_cx\_schedule\_sleep} is the actual implementation of the \textit{sleep} op. Like in\textit{Parrot\_cx\_preempt\_task}, \textit{Parrot\_cx\_stop\_task} is used to get an updated task at the current execution position, but instead of pushing this on the run queue, it is used as a callback for a newly set alarm. Again the NULL opcode is used to stop processing of the current task.

\section{Scheduler PMC (1)}

The Scheduler PMC contains the following attributes:
%
\begin{itemize}
\item PMC *task\_queue: List of tasks/green threads waiting to run
\item Parrot\_mutex task\_queue\_lock: a lock protecting the task\_queue so other threads might access it safely
\item PMC *alarms: List of future alarms ordered by time
\item PMC *all\_tasks: Hash of all active tasks by ID
\item UINTVAL next\_task\_id: ID to assign to the next created task
\item Parrot\_Interp interp: A reference to the scheduler's interpreter.
\end{itemize}

\textit{push\_pmc} and \textit{unshift\_pmc} are used to add a task at the end respectively the beginning of the task\_queue. \textit{shift\_pmc} is used to fetch and remove a task from the tip of the \textit{task\_queue}. \textit{get\_integer} returns the number of tasks in the \textit{task\_queue}. These four methods use the \textit{task\_queue\_lock} to make accessing the \textit{task\_queue} thread safe. Thus the Scheduler PMC acts as a container while using \textit{task\_queue} to actually store the data.

\textit{alarms} is list containing all pending alarms, sorted by their expiry time. Sorted insertion is used to keep alarms in order. Sorting makes it simple and efficient to retrieve all alarms that have expired at a certain point in time.

The \textit{active\_tasks} returns an array containing all tasks which have been run at least once and are not yet finished, e.g. they are currently being executed or are preempted.

\section{Task PMC}

The Task PMC contains the following attributes:
%
\begin{itemize}
\item UINTVAL id: Unique identifier for the task
\item FLOATVAL birthtime: The creation time stamp of the task
\item Parrot\_Interp interp: The interpreter which created the task
\item PMC *code: The code to run
\item PMC *data: Additional data for the task given as parameter to \textit{code}
\item INTVAL killed: Flag marking killed tasks
\item PMC *waiters: Tasks waiting on this one
\item PMC *shared: List of variables shared with this task
\item PMC *partner: Copy of this task on the other side of a GC barrier, meaning in another thread
\end{itemize}

The \textit{invoke} method is used to run the task. It first checks the \textit{killed} flag to see if the task has been killed while waiting in the task queue. If it's still alive, the current recursion depth is saved to a local variable. This is a workaround needed because \textit{Parrot\_Sub\_invoke} which ends up being called when invoking the task's \textit{code} increments the recursion depth, but it does not get decremented anymore in case the task got preempted. This would lead to an ``recursion depth exceeded'' exception when many tasks are invoked during a program's runtime. The next steps are to add the task to the list of active tasks and to invoke the task's \textit{code}. \textit{data} is an optional parameter to the subroutine given as \textit{code}. Since this may be a compound object, a single parameter can cover all use cases.

If the task has been killed while being in the task queue or while running or it just ended, it gets removed from the list of active tasks and all tasks registered with this task's \textit{waiters} array are added to the scheduler's task queue to be run.

\textit{push\_pmc} and \textit{pop\_pmc} are used to add or remove variables to the task's list of shared data. For these variables, proxies will be created when the task is run on a different thread.

The \textit{kill} method is used to set the task's \textit{killed} flag.

\section{Runloops (1)}

Runloops are created whenever a part of Parrot's C internals starts to execute bytecode. This could be simply at interpreter startup to start the actual program to execute or when some library function needs to execute a user callback. An exception handler could also be such a callback. Each runloop has a unique id. These ids are numbered from 0 and simply increased by 1 whenever a new runloop is created.

When an exception is thrown, Parrot searches for a previously set up exception handler and executes it. As part of exception handling finalization, it cleans up, freeing any information no longer needed. The exception handler does not necessarily have to have been set up in the same runloop which the exception has been thrown from. Parrot uses the runloop id to identifiy such situations and free the nested runloops up to the level of the exception handler.

A continuation also contains the id of the runloop in which it has been created. When resuming a preempted task, this id would not be the same as the one of the runloop created for executing its code. This would lead to Parrot not finding the correct runloop when finalizing an exception.

To mitigate this, the \textit{reset\_runloop\_id\_counter(interp)} function is used by \textit{Parrot\_cx\_outer\_runloop} to reset the global runloop id counter back to 0 when resuming a task. This way the task retains the same runloop id over its life time.

If Parrot were to preempt a task while it is executing a nested runloop, it would have to somehow capture not only the interpreter's current state but also the C stack between the outermost runloop and the currently executing one. It would also have to recreate these call and runloop stacks when resuming the task. Otherwise the task would be ended as soon as the executing callback would be completed since instead of some C function called by an op in the bytecode, the scheduler is the owner of the runloop.

Thus the scheduler checks for the current runloop id and does not preempt a task if it is currently running a nested runloop. Furthermore even a manual yield to another task is not possible in such a situation. The only way to solve this problem would be to get rid of nested runloops in the interpreter.

\section{Threads (8)}

\subsection{Creation (1)}
\label{subsec:thread_creation}

Each thread is represented by an instance of the ParrotInterpreter PMC. These interpreters are kept in the \textit{threads\_array} defined in \textit{src/thread.c}. It's a simple C array instead of one of Parrot's dynamic arrays which are implemented as PMCs because though ParrotInterpreter is implemented as a PMC itself, it's not fully garbage collected because of the bootstrapping issues this would create.

\textit{src/thread.c} also contains thread management functions all prefixed by \textit{Parrot\_thread\_}. Threads are created when \textit{Parrot\_cx\_schedule\_task} determines that all existing threads are busy and new threads may yet be started. It uses \textit{Parrot\_thread\_create} which creates a new interpreter by cloning the current one but with a cleared out \textit{thread\_data} structure. It also creates the \textit{thread\_data->notifierfd} pipe used to notify threads of expired alerts.

The task is then scheduled with the new interpreter's scheduler using \textit{Parrot\_thread\_schedule\_task}. This function uses \textit{Parrot\_thread\_create\_local\_task} to create a corresponding task on the new interpreter and then simply pushes it onto the scheduler. Since each interpreter has its own garbage collector, all objects used on the interpreter must origin from this GC's memory pools. That's why \textit{Parrot\_thread\_create\_local\_task} creates a new \textit{local\_task}. Proxies are created for the task's \textit{code} and \textit{data} attributes. The task object of the originating interpreter and the new \textit{local\_task} are linked using their \textit{partner} attributes which just contains a pointer to the other object. This is the point where for all variables in the original task's \textit{shared} array proxies are created an put into the \textit{shared} array of the \textit{local\_task}. \textit{Parrot\_thread\_create\_proxy} is used for this purpose.

\textit{Parrot\_thread\_insert\_thread} is used to put the new interpreter into the \textit{threads\_array}.

\textit{Parrot\_thread\_run} is the function where the actual operating system thread is created. It uses macros defined in the \textit{include/parrot/thr\_*.h} include files which act as an OS abstraction layer.

\textit{Parrot\_thread\_outer\_runloop} is used as the thread's main function. It's very similiar to \textit{Parrot\_cx\_outer\_runloop}. The most important difference is the way it waits for pending alarms in case no tasks are to be run. While \textit{Parrot\_cx\_outer\_runloop} waits for an alarm signal to arrive, \textit{Parrot\_thread\_outer\_runloop} waits for a dummy to be written to its \textit{notifierfd} pipe by \textit{Parrot\_cx\_run\_scheduler}. In addition it's holding the \textit{interp->thread\_data->interp\_lock} lock while executing a task. This is the lock which \textit{Parrot\_cx\_schedule\_task} is taking during its call to \textit{Parrot\_thread\_schedule\_task} because the latter needs to create new objects local to the thread. As this could cause garbage collection to be triggered, the thread itself should not be executing code at the same time.

\subsection{Proxies (2)}

Proxies are the arbiters between threads. They are the only means for a thread to access another thread's data and are implemented by the \textit{Proxy} PMC type. This type has only to attributes, none of which are garbage collected:
%
\begin{itemize}
\item PMC *target: The PMC this object proxies to
\item Parrot\_Interp interp: The interpreter owning target
\end{itemize}

As described in section~\ref{sec:PMCs} PMC source files to get preprocessed before compilation by a C compiler. This preprocessing gets done by the \textit{tools/build/pmc2c.pl} Perl script. This script got extended by implementing the \textit{Parrot::Pmc2c::PMC::Proxy} module which creates default implementations for all vtable functions not otherwise defined in the \textit{proxy.pmc} file. The default implementation for all writing functions would just call \textit{cant\_do\_write\_method} which creates a runtime exception. All other methods call the vtable method of the same name on the \textit{target} passing \textit{interp} as the current interpreter and all other parameters unchanged. If the method returns a PMC, another proxy object is created and wrapped around it so it may be safely returned to the caller.

\subsection{Writing shared data (2)}

As described in chapter~\ref{cha:design} to write to shared data, a thread creates a small task and schedules it on the data owning interpreter. An example task could look like this:
%
\begin{GenericCode}
.sub write_to_variable
    .param pmc variable
    variable = 1
.end
\end{GenericCode}
%
This is a subroutine with just one parameter. The variable passed in as this parameter is the one the task should write to. In this case the constant value 1 would be written to the variable. In PIR an assignment to a PMC gets translated as a method call. In this case the \textit{set\_integer\_native} would be called changing the variable's value. Since PMCs get passed by reference, it's the original variable which gets written to.

The code to create the task would look like:
%
\begin{GenericCode}
    write_task = new ['Task']
    setattribute write_task, 'code', write_to_variable
    setattribute write_task, 'data', shared_variable
    interp.'schedule_proxied'(write_task, shared_variable)
\end{GenericCode}
%
Line 1 simply creates a new Task object. The example subroutine is used for the task's \textit{code} attribute. \textit{shared\_variable} is used for \textit{data}. At this point \textit{shared\_variable} is actually the proxy object created for the shared integer PMC. The interpreter object contains a \textit{schedule\_proxied} method which is used to schedule the \textit{write\_task} on the thread owning the original variable. This owner thread's interpreter cannot be used directly for scheduling the task, since it would have to be stored in a register to be accessible to PIR code. But then the same problem as described in subsection~\ref{subsec:thread_creation} would occur with the ParrotInterpreter PMC tripping up the garbage collector.

\textit{schedule\_proxied} uses \textit{Parrot\_thread\_create\_local\_task} which in this case detects that the \textit{data} given as parameter for the task's \textit{code} is actually a proxy already and unwraps the proxied object. \textit{Parrot\_cx\_schedule\_immediate} is then used to make the data owning interpreter execute the task as soon as possible.

\subsection{Garbage Collection (3)}

\chapter{Tests and Benchmarks (4)}

\chapter{Conclusion, Further Work and Experiences (3)}

\begin{itemize}
\item Windows implementation for timer/alarm handling
\item Replace thread\_data->interp\_lock usage by preallocated proxy objects
\item Allow threads to create threads
\item Allow multi level proxying (don't create a proxy for a proxy, unpack first)
\item Allow redistribution of tasks to other threads
\end{itemize}

\MakeBibliography{References, Literature (1)}

\include{messbox}
\end{document}
