\documentclass[bachelor,english]{hgbthesis}

\usepackage{wrapfig}
\usepackage{listings}
\AddBibFile{literature.bib}

\begin{document}

\title{Hybrid Threads for the Parrot Virtual Machine}

\author{Stefan Seifert}
\studiengang{Software Engineering}
\studienort{Hagenberg}
\abgabemonat{Februar}
\abgabejahr{2012}

\nummer{1010307037-A}
\gegenstand{SWE}
\semester{Wintersemester 2012}
\betreuer{Dr. Heinz Dobler}
\license{This work is published under the conditions of the Creative Commons Attribution 3.0 Unported License (CC BY) -- see \url{http://creativecommons.org/licenses/by/3.0/}}

\frontmatter
\maketitle
\tableofcontents

\chapter{Thanks (1)}

Andrew "whiteknight" Whitworth for laying the foundations for my work, being of tremendous help at all stages of the project and for fixing some of my bugs.

Nat "Chandon" Tuck for implementing green thread basics on which my work is based on.

Christoph "cotto" Otto for bringing me into the Parrot project.

Brian "benabik" Gernhardt for lurking in the IRC channel and at least trying to help with my many questions.

Markus "zimmski" Zimmerman for correcting many errors.

\chapter{Abstract (1)}

\begin{german}
\chapter{Kurzfassung (1)}
\end{german}

\mainmatter

\chapter{Introduction and Motivation (3)}

\begin{wrapfigure}{r}{0.5\textwidth}
A simple example of Perl:
\include{perlexample}
\end{wrapfigure}
%
On July 19th 2000, the Perl 6 design process was announced. Perl 5 had been a very flexible and widely used programming language but had started to show its age and suffered from early design decisions. The Perl interpreter is written in C and has accumulated a lot of cruft over the years. The general consensus among the core developers was that the code had reached a state where maintenance was approaching impossibility\cite{Masak40451}. An attempt to reimplement these internals had failed but led to the decision that the interpreter for a Perl 6 language should be developed independently of the needs of Perl 5. Since the Perl 6 syntax was very much in flux (and parts of it still are) the designers of these new internals tried to work very independently of any syntax related questions\cite{Developer}. Taking up the name born in an April Fool's Day joke announcing the merging of the Perl and Python programming languages, these new internals were called Parrot\cite{Perl}.

Parrot evolved from being just the interpreter for the new version of Perl to being a language independent virtual machine providing features like garbage collection, exception handling and dynamic typing. At the time when the Parrot project started, the Java and .NET virtual machines were widely used, but both targeted statically typed languages. Parrot thus filled a quickly growing niche.

The Perl 6 design process began with asking the Perl users for what they were expecting from the new version of the language. The very first feature that got asked for was well integrated multithreading support\cite{RFC1}. Perl 5 had two different implementations of thread support. In the first model, called 5005threads, data was shared by default and shared access to data had to be explicitly synchronized. This was similar to the models used by languages such as C or Java. The implementation however suffered from data corruption and crashes and thus was not recommended for production use\cite{ThreadManual}. Perl 5.6 introduced the newer model called ithreads, mostly as a way to emulate fork() on Win32 platforms. Perl 5.8 exposed this API (Application Programming Interface) to the user of the programming language. In this new model, all data is copied to each thread and afterwards thread local. Data must be explicitly shared between threads. In other words, in Perl threads are not lightweight at all. They have severe impact on memory usage, writes to shared data are expensive and still not all features of the language are usable in threaded programs.

Being born at a time when Perl 6 still looked much more similar to Perl 5 than it does nowadays, Parrot's threading support initially was very close to Perl's ithreads model. Previous attempts to change this into the more conventional model of data shared by default or implementing new technologies like Software Transactional Memory failed. For example Parrot has never supported running multiple threads and having garbage collection at the same time.

\section{Why is multithreading support so important?}

In the year 2005 development of faster CPUs (Central Processing Units) shifted from increased speed of a single core to adding more cores. Modern processors contain up to 12 cores with even mobile phones having up to four. To utilize a modern CPU's power, code needs to be run in parallel. In UNIX (and thus Perl) tradition, this is accomplished using multiple processes being a good solution for many use cases. For many others like Perl 6's auto threading of hyper operators, the cost of process setup and communication would be prohibitively high except for very large data sets.

\section{Why is multithreading support so difficult to implement?}

Low level programming languages like C provide only the bare necessities, leaving the responsibility for preventing data corruption entirely to the user. A high level language like Perl 6 on the other hand offers complex and compound data types, handles garbage collection and a very dynamic object system. Even seemingly simple things like a method call can become very complex sequences. In a statically typed programming language the definition of a class is immutable. Thus calling a method on an object contains just the steps of determining the object's class, fetching the required method from this class and calling it. Calling the same method again can then even omit the first two steps since their results cannot change.

In a dynamic language, the object may change its class at runtime. The inheritance hierarchy of the class may be changed by adding or removing parent classes. Methods may be added to or removed from classes (or objects) at runtime and even the way to find a method of a class may change. So a simple method call results in the following steps:
%
\begin{itemize}
\item determining the class of the object
\item determining the method resolution method of the class
\item finding the actual method to call
\item calling the method
\end{itemize}
%
These steps have to be repeated for every following method call, because their results may change any time. In a threaded environment, a thread running in parallel may change the underlying data and meta data in between those sequences and even between those steps. As a consequence, this meta data has to be protected from corruption introducing the need for many locks in a very performance critical area.

Many interpreters for dynamic languages like Python or Ruby handle this problem by using a global interpreter lock to effectively serialize all operations. This is a proven and reliable way but again leaves much of the hardware's potential unused.

\section{Current status}

During these years of back and forth and failed attempts of adding threading support to Parrot, the Perl 6 specification evolved to a point where the largest parts of the language were covered and its features implemented in the compilers. The lack of concurrency primitives in Parrot however prevents any progress in the area of concurrency support.

Before the work on this paper, Parrot did not have any threading support at all. The previous, defunct implementation had been removed.

This paper suggests a new approach based on a hybrid threading system. So called green threads are used to simplify the implementation of a nearly lock free multithreading implementation. This approach is based on a design by Andrew Whitworth and Nat Tuck. The goal of this paper is to demonstrate the advantages of this model and produce a working implementation which can be used to investigate the performance characteristics of a hybrid threading system.

\chapter{Concurrency in other Programming Platforms (5)}

This chapter is talking about programming platforms. A platform is seen as a combination of a programming language and a runtime. For example for the Python programming language there are multiple runtimes with different implementations of threading support.

\section{Java}

In Java responsibility for preventing concurrency issues is obliged on the user code. The language provides synchronization primitives like mutexes, but the interpreter (the Java Virtual Machine, JVM) does not protect itself. The class library provides the user with high level data structures explicitly designed for multithreaded scenarios.

Java version 1.1 used ``green threads'' to support multithreaded execution of Java programs. Green threads are threads simulated by the virtual machine but unable to use more than one CPU core for processing. Details are described in chapter~\ref{cha:green_threads}. Version 1.2 introduced native OS (Operating System) thread support which since has become the standard way to do multithreading in Java\cite{JavaThreadManual}.

\section{Python}

Python provides threading support through the \textit{threading} module.

The CPython implementation of the Python runtime uses a Global Interpreter Lock (GIL) to protect its internal consistency\cite{PythonThreadingManual}. This is a single lock taken whenever the interpreter executes Python bytecode. Because of this lock, only one thread can execute bytecode at any time so all built-in types and the object model are implicitly type safe. The drawback is that Python code cannot benefit from having multiple CPU cores available. However I/O operations and calls to external libraries are done without holding the GIL, so in applications with multiple I/O bound threads, there may still be a performance benefit from using multithreading.

To actually run Python code in parallel, multiple processes have to be used. The \textit{multiprocessing} module provides support for spawning processes using an API similar to the threading module\cite{PythonMultiProcessingManual}. Since processes may not directly access other processes' memory, the \textit{multiprocessing} module provides several means of communication between processes: \textit{Queues}, \textit{Pipes} and shared memory support.

\chapter{Parrot (4)}

Parrot consists of the virtual machine (VM, also called interpreter), and various tools to facilitate the implementation of programming languages on top of the Parrot VM (the Parrot Compiler Toolkit). This paper concentrates on the virtual machine itself. The interpreter itself is written in C. Example code and test cases are written in PIR (Parrot Intermediate Representation) a high level assembly language abstracting away register allocations and function calling conventions.

Contrary to other widely used virtual machines like the JVM or the CLR which are stack based, Parrot mirrors contemporary hardware CPUs more closely by being register based. A stack based virtual machine usually fetches the operands of an operation from the top of a stack and puts the result back on top. Thus the operands are chosen implicitly by ordering of the operations allowing the opcodes to be quite small. In a register based VM on the other hand each operation has to specify the operands explicitly. Compilers for stack machines are simpler because they do not have to care about register allocations and code is independent of prior or subsequent code\cite{VMShowdown}. The rationale behind giving up the simplicity of a stack based implementation is the hope of simplifying just in time compilation and improved performance of nested function and method calls.

The current design uses four sets of registers with each and unlimited number of usable registers. The four sets are:
%
\begin{itemize}
\item integer
\item floating point
\item string
\item polymorphic container (PMC)
\end{itemize}

The first three should be self explanatory. Strings in Parrot are a low level type with the interpreter handling all memory allocation issues and Unicode encoding. String values themselves are immutable.

\section{PMCs}
\label{sec:PMCs}

PMCs (PolyMorphic Container) are containers for all higher level types such as objects, arrays, hash tables or code. Thus they are very similar to Python's PythonObject types. PMCs are defined by C structs and are fully garbage collected. Their definition looks like:
\begin{CCode}
struct PMC {
    Parrot_UInt    flags;
    VTABLE         *vtable;             /* Pointer to vtable. */
    DPOINTER       *data;               /* Pointer to attribute structure. */
    PMC            *_metadata;          /* Pointer to metadata PMC. */
};
\end{CCode}
In short they contain a pointer to a type specific data structure and some meta data. The vtable is where the type's behavior is defined. It contains a long list of function pointers forming Parrot's unified type interface. This interface is a union of numeric, string, array, hash and object like behaviors. For example the  \textit{get\_integer} function returns an integer value for the data type. For a simple \textit{int} it is the contained value. For an array it may be the number of elements. The \textit{find\_method} function makes user defined methods of objects possible.

In this way, a language implementer can define the basic types of the language and available operations on them. For each vtable entry, there is a corresponding op code in Parrot's bytecode. Thus an \textit{inc \$P0} instruction is calling the \textit{increment} vtable function of the PMC contained in the \textit{\$P0} register.

PMCs are implemented in .pmc files with method bodies written in C. These files get preprocessed to plain C before compilation.

\section{ParrotInterpreter}

The interpreter itself is represented by a C struct called \textit{parrot\_interp\_t}. This structure contains pointers to the garbage collector's runtime data, the loaded types, vtables, the runloop, the current continuation and other global data. A pointer to this structure is passed to almost every function as the first parameter.

\section{Continuation passing}

Control flow in Parrot is modeled using continuation passing. A continuation is a data structure containing the state of a program at a given point in its execution. It contains all information needed to continue a program in a certain state, e.g. a call stack, the instruction pointer and contents of local variables. ``Calling'' a continuation means restoring the state encapsulated in the continuation.

When a function is called, instead of pushing all this information on the stack, the function is given a return continuation as part of its parameters. Returning from a function means calling the return continuation with possible return values stored in the registers where the calling code is expecting them. Continuation passing makes things like tail call optimization \footnote{When as the last statement of a function another function is called and its value returned unchanged, the outer function can just pass on its return continuation thus saving the need to create a new continuation and one step on returning from the nested function} very simple and as described in chapter~\ref{cha:green_threads} is a very important piece in implementing green threads.

\section{Runloops}
\label{sec:Runloops}

A runloop is in principle the inner most loop executing bytecode in Parrot. It is also a data structure containing some information needed to support exception handling. When some operation in Parrot bytecode is calling a C function and this C function in turn is again executing Parrot bytecode, a nested runloop is started. Examples for such situations include calling a library function with a callback as parameter and exceptions thrown inside Parrot's C code calling a previously defined exception handler in user code.

\section{Exception handling}

Before entering a runloop, the \textit{setjmp} C function is used to save the current stack position and register contents to a data structure stored in the runloop meta data. This is effectively creating something resembling a continuation at C level. When an exception is created within the interpreter, the runloop stack is searched for the runloop containing a suitable exception handler. \textit{longjmp} is then used to unwind the call stack up to the point where setjmp was called and the call environment restored. While having great similarities with continuations, this mechanism is more limited. It only allows to jump back to a point higher in the call stack.

\section{Garbage Collector}

Parrot supports different GC (Garbage Collector) implementations which can be selected at interpreter startup. Currently there are four existing implementations of different algorithms:
\begin{itemize}
\item Inf: a GC for debugging purposes never collecting any garbage
\item MS: a basic mark and sweep implementation
\item MS2: a non-recursive mark and sweep implementation
\item GMS: a generational, non-compacting, mark and sweep GC
\end{itemize}
with GMS being the default.

A mark and sweep garbage collector operates in two phases. In the mark phase, starting from a known root set of objects, the GC follows pointers down the object tree, marking each encountered object as alive. In the sweep phase, all objects not being alive are destroyed and the live flags reset.

In a process with many objects, having to traverse the whole tree may take a considerable amount of time. To mitigate this, a generational garbage collector extends this algorithm by assuming that the longer an object has lived, the lower the chances are that it will become unused. So the objects are partitioned into different generations. The youngest generation would always be traversed while the older generations would be handled much less frequently or even never more at all.

\section{Historical development (1)}

The remainder of the previous threading implementation has been removed with the merging of the kill\_threads branch on September, 21st 2011. Previously much threading related code has been removed to clean up the code and improve performance. Since the existing threading support was known to be unreliable and seriously flawed, this was no trade off.

A year before, Nat Tuck began working on a green\_threads branch during his Google Summer of Code internship. The feature got prototyped using pure PIR and then implemented in Parrot's core. He got it to work in simple cases and started to work on operating system thread support but the internship ended before the code was ready to be merged into the master branch. The code lay dormant until the work on this paper started about a year later.

\chapter{Green threads (3)}
\label{cha:green_threads}

Green threads are one way to model concurrent control flows in a program. To get a better understanding of what they are and how they work, the possible options are discussed first.

\section{Coroutines}

Coroutines are functions retaining their state between calls. Instead of returning, they yield control back to the calling function, possibly with an intermediate result returned. A very simple example in Python looks like:
\begin{GenericCode}
def counter():
    for i in range(0, 100):
	yield i
\end{GenericCode}
This function would return one integer for every call, counting from 0 to 100. An example usage would look like:
\begin{GenericCode}
x = counter()
print x
x = counter()
print x
\end{GenericCode}
This example would print the numbers 0 and 1. For the two functions to run in parallel, they have to cooperate. One by calling the other repeatedly and the callee by yielding control back to the caller.

\section{Operating system threads}

Operating system threads are like multiple processes running at the same time but share their memory. The operating system is responsible for giving each of these threads CPU time to run. Operating system threads are the only of these options where more than one thread may be executed by the CPU(s) at the same time if the hardware permits.

\section {Green threads}

"Green threads" or "lightweight threads" are threads managed by the virtual machine instead of by the operating system. For better distinction green threads are henceforth referred to as "tasks". These tasks only run pseudo parallel. The virtual machine contains a scheduler and support for preempting running tasks.
Preemption means to suspend a task regardless of what it is currently doing and probably resuming it later on.
This is an implementation of the many-to-one threading model very similar to what an operating system running on a system with a single CPU core does.
%
Advantages of green threads are:
%
\begin{itemize}
\item They allow pseudo concurrent processing without endangering the interpreter's internal consistency.
\item Green threads are very light weight with low memory overhead and close to zero creation time.
\item They do not depend on OS threading support
\item The interpreter controls the point of preemption of a green thread.
\item The interpreter controls the exact scheduling policy and may allow the user to influence it or even take over completely.
\item Garbage collection can be implemented like in a single threaded process.
\item Critical sections can simply be protected by disabling the scheduler until the code is clear of the section.
\end{itemize}
%
Disadvantages include:
%
\begin{itemize}
\item They do not allow more than one CPU core to be used for computations.
\item Blocking calls like I/O block the whole interpreter including other green threads.
\item The interpreter has to contain logic and timers to control green threads.
\end{itemize}

Green threads differ from coroutines in that the interpreter decides when a running task is to be preempted while a coroutine depends on manual yield calls.

Following is a simple example to explain why concurrent processing can endanger the interpreter's internal consistency. The basic problem is concurrent writes to shared data. Assuming an implementation of an array class consisting of the field holding the data and the number of contained elements in a separate member variable:
\begin{CCode}
pmclass ResizableIntegerArray auto_attrs provides array {
    ATTR INTVAL   size;      /* number of INTVALs stored in this array */
    ATTR INTVAL * int_array; /* INTVALs are stored here */
\end{CCode}
to append a new value, the array would have to read the current size, write the new value at the position size + 1 and then write the incremented size back into the member variable.
Now if two threads simultaneously try to do this, it may happen that both read the same size, write to the same position (with one overwriting the value of the other) and write back the same incremented size. In this case one of the appended values would be lost.

In a more complicated example, the array could have to resize its data buffer to accommodate the new value. It would read the current size, allocate a new buffer, copy the values to the new buffer and then destroying the old one. Again if two threads try to do this simultaneously, one of them could still be copying data, while the other is already at the point where it destroys the old buffer. This would lead to the copying thread accessing freed memory.

When garbage collection is brought into the mix, the possibilities for corruption grow even more. At the point where the first thread needs to allocate the new buffer, the garbage collector could decide that it needs to run and clear some unused memory. It would have to traverse the object tree to mark alive objects. Between the mark and the sweep runs, the second thread could change the pointer to the buffer from the old one to the new one. So the old buffer would have been marked alive, while during the sweep run the new buffer would be in its place, but not yet marked alive.

\section{Green threads in Parrot}

Parrot's green threads implementation is based on Nat Tuck's green\_threads branch developed during his Google Summer of Code internship.

In Parrot green threads are called \textit{Task}. Each task is assigned a fixed amount of execution time. On expiry a timer callback sets a flag which is checked for at execution of every branch operation. Since the interpreter's state is well defined at this point, its internal consistency is guaranteed. The same goes for the garbage collector. Since task preemption is only done while executing user level code, the GC can do its work undisturbed and without the need for measures like locking. Since user level code is allowed to disable the scheduler, it can be guaranteed to run undisturbed through critical sections.

The scheduler is implemented as a PMC (Parrot's polymorphic container) type. The plan is to allow the user to subclass this PMC thus allowing very fine grained control over the scheduling policy. Features a user could add this way would be for example giving different priorities to tasks or implementing the possibility to suspend and resume a task.

\chapter{Design of Hybrid Threads (3)}
\label{cha:design}

This chapter describes how green threads were used to solve the following problems occurring when trying to implement threading support:
%
\begin{itemize}
\item How to ensure internal interpreter consistency when doing writes to shared data.
\item How to implement critical sections.
\item How to handle garbage collection.
\end{itemize}

In keeping the analogy of the interpreter being a software CPU, multithreading is implemented by having a separate interpreter with its own register set for each thread. Thus the words ``thread'' and ``interpreter'' are used interchangeably as there is a 1:1 relationship between them. When a user starts a new task, the scheduler first looks for an idle thread. If one can be found, the task is scheduled on the thread's interpreter. If none can be found, a new thread with a new interpreter is started. Parrot tries to optimize the number of utilized threads by creating at most one for each CPU core in the system. If more tasks are started than the maximum number of threads, the tasks are distributed evenly among the running interpreters. This is effectively an implementation of the N:M threading model.

\section{Shared data}

As described in the introduction, cross thread writes to shared data may endanger the internal consistency of the interpreter. Traditionally the response to this problem is the use of locks of varying granularity. Fine grained locking allows code to run well parallelized but taking and releasing locks also costs performance. It not only increases the instruction count and memory accesses but it also forces the CPU cores to coordinate and thus communicate. Even a seemingly simple operation like an atomic increment can take two orders of magnitude longer than a normal increment\cite{LockingInOSKernels}. While the gain through being able to utilize multiple CPU cores may offset this cost, it is still impacting the very common case of having only a single thread running.

Too coarse locking on the other hand would reduce scalability and the performance gains through parallel execution by having threads wait for extended periods for locks to become open. In the extreme case of having a global interpreter lock it would even effectively serialize all computations costing much of the benefits of using threads in the first place.

The other problem with locking is the possibility of introducing dead locks. For example, two functions F1 and F2 both use two resources A and B protected by locks. If F1 first locks A and then tries to lock B while F2 has already locked B and is now trying to lock A, the program would come to a halt. Both functions would be left waiting for the other to unlock the resource which will never happen. With fine grained locking the possibilities for such bugs grow quickly. At the same time it is easy to miss a case where a lock would be appropriate leading to difficult to diagnose corruption bugs.

The solution for these problems implemented for this paper is to side step them altogether by disallowing write access to shared data. The programmer (or in most cases the compiler) is obliged to declare a list of all shared variables before a newly created task is started. The interpreter would then create proxy objects for these variables which the task can use to access the data. These proxies contain references to the original objects. They use these references to forward all reading vtable functions to the originals. Write access on the other hand would lead to a runtime error.

In other words all data is owned by the thread creating it and only the owner may write to it. Other threads have only read access.

For threads to be able to communicate with their creators and other threads, they still need to write to shared data. This is where green threads come into play. Since green threads are very light weight, it is feasible for a thread to create a task just for updating a variable. This task would be scheduled on the interpreter owning this variable. To reduce latency, the task is flagged to run immediately. The data owning interpreter would preempt the currently running task and process the new write task. Put another way, the data owning interpreter is simply told what to write to its variables, so other threads don't have to.

\section{Critical Sections}

In this scheme critical sections can simply be implemented by disabling preemption till the code is clear of the section. With other threads not being allowed to write to the data and the current task running uninterrupted it it guaranteed to complete without the data being changed from outside.

\section{Garbage Collection}

A garbage collector has to traverse and process the entire tree of objects in memory. If during this traversal another thread is changing this tree by creating new objects, moving them around in the tree or removing them, the garbage collector's data would be compromised. For example it could happen that the GC does not mark referenced objects alive because they were added to parents having already been processed.

In previous attempts to implement threading support in Parrot, the answer to this problem was to disable the garbage collector while multiple threads are active. While multithreaded garbage collection algorithms exist, their implementation would have been too complex and brittle for this paper\cite{VCGC}. Other VMs solve this problem by suspending all threads while the GC is running. Suspending all threads is not as simple as it sounds because these threads can be in any state at the time. For example, they could be blocking on some long running I/O operation like waiting for a reply on a network connection. A thread can stay in this condition indefinitely thereby never being able to confirm synchronization.

Since cross threaded writes are already forbidden and all read access to other thread's data goes through the very narrow channel of proxy objects, forcing a complete separation of the thread's memory domains was only a small step. By having separate memory areas for each interpreter, it became possible to have each interpreter to run its own garbage collector. This way, the known to work, single threaded GC implementation can be used nearly unchanged.

With separated memory domains it can happen that an object is created on one thread, used on another thread but not any more on the owner thread. Without any additional measures, the GC would collect such objects, since it does not know about references from other threads. But since all objects which could be accessed from other threads have to be pushed onto the Task object representing these threads, the objects can still be referenced from the Task object. Since the task is still owned by the original thread, the GC knows that these objects are still in use.

\chapter{Implementation of Hybrid Threads (13)}

\section{The Scheduler (3)}

The scheduler is the place where most of the green thread logic is implemented. It consists of two parts: functions using the prefix \textit{Parrot\_cx} which are located in \textit{src/scheduler.c} and the Scheduler PMC type containing the scheduler's data and public interface.

\textit{Parrot\_cx\_init\_scheduler} is called from \textit{Parrot\_interp\_initialize\_interpreter} whenever a new interpreter is created, e.g. on interpreter startup and whenever a new thread is created. It creates the scheduler PMC and sets up alarm signal handling.

The scheduler is hooked into the system by replacing the call to execute the \textit{main\_sub} by a call to \textit{Parrot\_cx\_begin\_execution}. The latter creates the main task using \textit{main\_sub} as the task's code. This task is then put onto the run queue. The scheduler timer gets enabled and control given to \textit{Parrot\_cx\_outer\_runloop}.

\textit{Parrot\_cx\_outer\_runloop} is the core loop taking tasks from the run queue and executing them. Despite its name, it should not be confused with runloops discussed in section~\ref{sec:Runloops}. \textit{Parrot\_cx\_outer\_runloop} actually consists of two nested loops. The inner loop simply fetches tasks and executes as long as tasks are available. Even when all tasks are finished there may still be alarms pending which upon expiry would trigger new tasks to be scheduled. For this reason there's an outer loop checking for pending alarms and if there are putting the thread to sleep until the next alarm expires.

\textit{Parrot\_cx\_next\_task} contains the code to take the next task from the run queue and executing it. Before calling the task, it checks if there are other tasks still in the queue. Only if other tasks are waiting, task preemption gets enabled. Otherwise the current task would run until it finishes by itself, schedules other tasks or an alarm expires. This is an optimization reducing the runtime overhead of green threads in the important single tasking case to 0.

To enable task preemption, \textit{Parrot\_cx\_enable\_preemption} sets a flag on the scheduler PMC and uses \textit{Parrot\_cx\_set\_scheduler\_alarm} to set an alarm at a point \textit{PARROT\_TASK\_SWITCH\_QUANTUM} milliseconds in the future.

When an alarm is triggered, Parrot only increments the global \textit{alarm\_serial}. This serial is checked for changes by \textit{Parrot\_alarm\_check} being called by \textit{Parrot\_cx\_check\_scheduler}. This function in turn is called once for every \textit{branch} op. When the serial is different from the last check or the \textit{SCHEDULER\_wake\_requested} flag is set, \textit{Parrot\_cx\_check\_scheduler} wakes the scheduler by calling \textit{Parrot\_cx\_run\_scheduler}.

Since POSIX alarms can only be delivered to the main thread of a process, \textit{Parrot\_cx\_run\_scheduler} uses \textit{Parrot\_thread\_notify\_threads} to relay alarms to other thread's schedulers. For this purpose every thread has a pipe which \textit{Parrot\_thread\_notify\_threads} writes a dummy byte to. The next step for \textit{Parrot\_cx\_run\_scheduler} is to check for any expired alarms using \textit{Parrot\_cx\_check\_alarms}. An alarm contains a task as callback. On expiry this callback gets scheduled for immediate execution. As alarm signals do not contain any information about their origin, the scheduler does not know if the alarm was scheduled by user code or if it is the scheduler's preemption alarm. \textit{Parrot\_cx\_check\_quantum} is therefore used to check if the current task has used its assigned quantum and if it should be preempted.

Preemption of a task is implemented in \textit{Parrot\_cx\_preempt\_task}. It uses \textit{Parrot\_cx\_stop\_task} to create a continuation at the current point of execution and store it as the task's code. The task itself is then appended at the end of the run queue. The NULL opcode return value is propagated all the way up through the stack back to the \textit{branch} op checking for alarms. The op then recognizes this as the signal to stop processing and to exit the runloop.

The control flow ends up back at \textit{Parrot\_cx\_next\_task} at the point after executing the task. \textit{Parrot\_cx\_next\_task} then returns to \textit{Parrot\_cx\_outer\_runloop}.

The \textit{schedule} op code is used to schedule a new task from user code. It uses \textit{Parrot\_cx\_schedule\_task} which starts new worker threads if needed and possible and pushes the task on the target thread's scheduler's task queue. If the target thread previously was executing only a single task, its preemption has been disabled for optimization as described above. So in this case \textit{Parrot\_cx\_schedule\_task} has to enable preemption to give the new task a chance to run.

\textit{Parrot\_cx\_schedule\_immediate} is used in various places like at alarm expiry for putting a task to the head of the run queue and immediately causing preemption of the currently running task. It does this by setting \textit{SCHEDULER\_wake\_requested} and \textit{SCHEDULER\_resched\_requested} flags the same as when the preemption alarm expires. To be precise this mechanism leads to the current task being preempted at the next \textit{branch} op since this is the place when the mentioned flags will be checked.

Alarms can be registered using \textit{Parrot\_cx\_schedule\_alarm}. It puts the alarm in the appropriate place in the ordered alarm list and uses \textit{Parrot\_alarm\_set} which sets the actual alarm but only if there's not another alarm already set for an earlier time since there can only be one POSIX alarm pending at any time.

\textit{Parrot\_cx\_schedule\_sleep} is the actual implementation of the \textit{sleep} op. Like in \textit{Parrot\_cx\_preempt\_task}, \textit{Parrot\_cx\_stop\_task} is used to get an updated task at the current execution position, but instead of pushing this on the run queue, it is used as a callback for a newly set alarm. Again the NULL opcode is used to stop processing of the current task.

\section{Scheduler PMC (1)}

The Scheduler PMC contains the following attributes:
%
\begin{itemize}
\item PMC *task\_queue: List of tasks/green threads waiting to run
\item Parrot\_mutex task\_queue\_lock: a lock protecting the task\_queue so other threads can access it safely
\item PMC *alarms: List of future alarms ordered by time
\item PMC *all\_tasks: Hash of all active tasks by ID
\item UINTVAL next\_task\_id: ID to assign to the next created task
\item Parrot\_Interp interp: A reference to the scheduler's interpreter.
\end{itemize}

\textit{push\_pmc} and \textit{unshift\_pmc} are used to add a task at the end respectively the beginning of the task\_queue. \textit{shift\_pmc} is used to fetch and remove a task from the tip of the \textit{task\_queue}. \textit{get\_integer} returns the number of tasks in the \textit{task\_queue}. These four methods use the \textit{task\_queue\_lock} to make accessing the \textit{task\_queue} thread safe. Thus the Scheduler PMC acts as a container while using \textit{task\_queue} to actually store the data.

\textit{alarms} is list containing all pending alarms, sorted by their expiry time. Sorted insertion is used to keep alarms in order. Sorting makes it simple and efficient to retrieve all alarms that have expired at a certain point in time.

The \textit{active\_tasks} returns an array containing all tasks which have been run at least once and are not yet finished, e.g. they are currently being executed or are preempted.

\section{Task PMC}

The Task PMC contains the following attributes:
%
\begin{itemize}
\item UINTVAL id: Unique identifier for the task
\item FLOATVAL birthtime: The creation time stamp of the task
\item Parrot\_Interp interp: The interpreter which created the task
\item PMC *code: The code to run
\item PMC *data: Additional data for the task given as parameter to \textit{code}
\item INTVAL killed: Flag marking killed tasks
\item PMC *waiters: Tasks waiting on this one
\item PMC *shared: List of variables shared with this task
\item PMC *partner: Copy of this task on the other side of a GC barrier, meaning in another thread
\end{itemize}

The \textit{invoke} method is used to run the task. It first checks the \textit{killed} flag to see if the task has been killed while waiting in the task queue. If it is still alive, the current recursion depth is saved to a local variable. This is a workaround needed because \textit{Parrot\_Sub\_invoke}, which ends up being called when invoking the task's \textit{code}, increments the recursion depth, but it does not get decremented anymore in case the task got preempted. This would lead to an ``recursion depth exceeded'' exception when many tasks are invoked during a program's runtime. The next steps are to add the task to the list of active tasks and to invoke the task's \textit{code}. \textit{data} is an optional parameter to the subroutine given as \textit{code}. Since this can be a compound object, a single parameter can cover all use cases.

If the task has been killed while being in the task queue or while running or it just ended, it gets removed from the list of active tasks and all tasks registered with this task's \textit{waiters} array are added to the scheduler's task queue to be run.

\textit{push\_pmc} and \textit{pop\_pmc} are used to add or remove variables to the task's list of shared data. For these variables, proxies will be created when the task is run on a different thread.

The \textit{kill} method is used to set the task's \textit{killed} flag.

\section{Runloops (1)}

Runloops are created whenever a part of Parrot's C internals starts to execute bytecode. This can be simply at interpreter startup to start the actual program to execute or when some library function needs to execute a user callback. An exception handler can also be such a callback. Each runloop has a unique id. These ids are numbered from 0 and simply increased by 1 whenever a new runloop is created.

When an exception is thrown, Parrot searches for a previously set up exception handler and executes it. As part of exception handling finalization, it cleans up, freeing any information no longer needed. The exception handler does not necessarily have to have been set up in the same runloop from which the exception has been thrown. Parrot uses the runloop id to identify such situations and free the nested runloops up to the level of the exception handler.

A continuation also contains the id of the runloop in which it has been created. When resuming a preempted task, this id would not be the same as the one of the runloop created for executing its code. This would lead to Parrot not finding the correct runloop when finalizing an exception.

To mitigate this, the \textit{reset\_runloop\_id\_counter(interp)} function is used by \textit{Parrot\_cx\_outer\_runloop} to reset the global runloop id counter back to 0 when resuming a task. This way the task retains the same runloop id over its life time.

If Parrot were to preempt a task while it is executing a nested runloop, it would have to somehow capture not only the interpreter's current state but also the C stack between the outermost runloop and the currently executing one. It would also have to recreate these call and runloop stacks when resuming the task. Otherwise the task would be ended as soon as the executing callback would be completed since instead of some C function called by an op in the bytecode, the scheduler is the owner of the runloop.

Thus the scheduler checks for the current runloop id and does not preempt a task if it is currently running a nested runloop. Furthermore even a manual yield to another task is not possible in such a situation. The only way to solve this problem would be to get rid of nested runloops in the interpreter.

\section{Alarms and Timers}

Timers used for \textit{sleep}, alarms and preemption use a common timer thread implemented in \textit{src/alarm.c}. This thread sleeps until a new alarm is set or the currently active one expires. When the latter happens it increases the global alarm serial and notifies all threads that a timer is expired. Since it does not keep a list of pending alarms but knows only about the next one, interpreter threads are obliged to re-set their next alarms upon notification.

\section{Threads (8)}

\subsection{Creation (1)}
\label{subsec:thread_creation}

Each thread is represented by an instance of the ParrotInterpreter PMC. These interpreters are kept in the \textit{threads\_array} defined in \textit{src/thread.c}. It's a simple C array instead of one of Parrot's dynamic arrays implemented as PMCs because though ParrotInterpreter is implemented as a PMC itself, it is not fully garbage collected because of the bootstrapping issues this would create.

\textit{src/thread.c} also contains thread management functions all prefixed by \textit{Parrot\_thread\_}. Threads are created when \textit{Parrot\_cx\_schedule\_task} determines that all existing threads are busy and new threads can yet be started. It uses \textit{Parrot\_thread\_create} to create a new interpreter by cloning the current one and giving it a cleared out \textit{thread\_data} structure. It also creates the \textit{thread\_data->notifierfd} pipe used to notify threads of expired alerts.

The task is then scheduled with the new interpreter's scheduler using \textit{Parrot\_thread\_schedule\_task}. This function uses \textit{Parrot\_thread\_create\_local\_task} to create a corresponding task on the new interpreter and then simply pushes it onto the scheduler. Since each interpreter has its own garbage collector, all objects used on the interpreter must origin from this GC's memory pools. That's why \textit{Parrot\_thread\_create\_local\_task} creates a new \textit{local\_task}. Proxies are created for the task's \textit{code} and \textit{data} attributes. The task object of the originating interpreter and the new \textit{local\_task} are linked using their \textit{partner} attributes containing a pointer to the other object. This is the point where for all variables in the original task's \textit{shared} array proxies are created an put into the \textit{shared} array of the \textit{local\_task}. \textit{Parrot\_thread\_create\_proxy} is used for this purpose.

\textit{Parrot\_thread\_insert\_thread} is used to put the new interpreter into the \textit{threads\_array}.

\textit{Parrot\_thread\_run} is the function where the actual operating system thread is created. It uses macros defined in the \textit{include/parrot/thr\_*.h} include files which act as an OS abstraction layer.

\textit{Parrot\_thread\_outer\_runloop} is used as the thread's main function. It's very similar to \textit{Parrot\_cx\_outer\_runloop}. The most important difference is the way it waits for pending alarms in case no tasks are to be run. While \textit{Parrot\_cx\_outer\_runloop} waits for an alarm signal to arrive, \textit{Parrot\_thread\_outer\_runloop} waits for a dummy to be written to its \textit{notifierfd} pipe by \textit{Parrot\_cx\_run\_scheduler}.

\subsection{Proxies (2)}

Proxies are the arbiters between threads. They are the only means for a thread to access another thread's data and are implemented by the \textit{Proxy} PMC type. This type has only two attributes, none of which are garbage collected:
%
\begin{itemize}
\item PMC *target: The PMC this object proxies to
\item Parrot\_Interp interp: The interpreter owning target
\end{itemize}

As described in section~\ref{sec:PMCs} PMC source files to get preprocessed before compilation by a C compiler. This preprocessing gets done by the \textit{tools/build/pmc2c.pl} Perl script. This script got extended by implementing the \textit{Parrot::Pmc2c::PMC::Proxy} module which creates default implementations for all vtable functions not otherwise defined in the \textit{proxy.pmc} file. The default implementation for all writing functions would just call \textit{cant\_do\_write\_method} which creates a runtime exception.

All other methods call the vtable method of the same name on the \textit{target} passing the current interpreter as \textit{interp} and all other parameters unchanged. This causes all access to globals by the proxied function to go through the thread's interp and new PMCs created during the call to be allocated from the thread's memory pool. If the method returns a PMC from the target's interp, another proxy object has to be created and wrapped around it so it can be safely returned to the caller.

To differ between PMCs originating from the target's \textit{interp} and those created on the thread's interp during the call the GC is told to set the new \textit{PObj\_is\_new\_FLAG} on newly created PMCs. The \textit{PARROT\_THR\_FLAG\_NEW\_PMC} flag on the interp itself is used to communicate this requirement to the GC.

The alternative of calling the proxied function using the target's \textit{interp} would lead to concurrency issues with the garbage collector. Any call may cause garbage collection to run. Since the GC also scans the C stack the target's GC would find the thread's PMCs there and mark them confusing the thread's GC. Disabling the garbage collector would require a lock since the target's GC may already have started collecting.

\subsubsection{Sub}

The \textit{Sub} PMC represents executable subroutines. A \textit{Sub} does not only contain the code to execute but also the context in which to execute the code such as visible globals and namespaces. If a proxy to such a \textit{Sub} were created and \textit{invoke} called on it, the code would access this context directly since it belongs to the same interp as the proxied \textit{Sub} itself. Thus an op like \textit{get\_global} would fetch a global from an unproxied namespace and an unproxied global would be put into the target register. Since this is happening while running \textit{invoke} on the original \textit{Sub}, \textit{Proxy} cannot intercept the call and create a \textit{Proxy} for the result.

This is the reason why \textit{Parrot\_thread\_create\_proxy} does not create a \textit{Proxy} for a \textit{Sub} but uses \textit{Parrot\_thread\_create\_local\_sub} to create a copy on the thread's \textit{interp} with proxies for all PMC attributes like \textit{namespace\_stash} and \textit{ctx}.

\subsection{Writing shared data (2)}

As described in chapter~\ref{cha:design} to write to shared data, a thread creates a small task and schedules it on the data owning interpreter. An example task looks like this:
%
\begin{GenericCode}
.sub write_to_variable
    .param pmc variable
    variable = 1
.end
\end{GenericCode}
%
This is a subroutine with just one parameter. The variable passed in as this parameter is the one the task should write to. In this case the constant value 1 would be written to the variable. In PIR an assignment to a PMC gets translated as a method call. In this case the \textit{set\_integer\_native} would be called changing the variable's value. Since PMCs get passed by reference, it is the original variable which gets written to.

The code to create the task would look like:
%
\begin{GenericCode}
    write_task = new ['Task']
    setattribute write_task, 'code', write_to_variable
    setattribute write_task, 'data', shared_variable
    interp.'schedule_proxied'(write_task, shared_variable)
\end{GenericCode}
%
Line 1 simply creates a new Task object. The example subroutine is used for the task's \textit{code} attribute. \textit{shared\_variable} is used for \textit{data}. At this point \textit{shared\_variable} is actually the proxy object created for the shared integer PMC. The interpreter object contains a \textit{schedule\_proxied} method which is used to schedule the \textit{write\_task} on the thread owning the original variable. This owner thread's interpreter cannot be used directly for scheduling the task, since it would have to be stored in a register to be accessible to PIR code. But then the same problem as described in subsection~\ref{subsec:thread_creation} would occur with the ParrotInterpreter PMC tripping up the garbage collector.

\textit{schedule\_proxied} uses \textit{Parrot\_thread\_create\_local\_task} which in this case detects that the \textit{data} given as parameter for the task's \textit{code} is actually a proxy already and unwraps the proxied object. \textit{Parrot\_cx\_schedule\_immediate} is then used to make the data owning interpreter execute the task as soon as possible.

To protect a critical section, preemption can be disabled so the critical section runs uninterrupted:
%
\begin{GenericCode}
.sub swap_variables
    .param pmc a, b
    .local temp
    disable_preemption
    temp = a
    a = b
    b = temp
    enable_preemption
.end
\end{GenericCode}

\subsection{The \textit{wait} op}

Using \textit{Tasks} to write to write to shared data makes such actions inherently asynchronous. This is not always what is needed by the implemented algorithm. For example when the shared variable is a lock, processing should continue as soon as it's acquired. The \textit{wait} op is used to wait for a task's completion. The waiting task is added to the waited for task's \textit{waiters} list and preempted immediately. When a task finishes, the all tasks in the \textit{waiters} list are scheduled again for execution. Since for each task a local copy is created on the target thread, the running task not only checks its own \textit{waiters} list but also its partner's.

If a task on the main thread was waiting for a task on another thread to finish and no other tasks are in the scheduler's queue on the main thread, the main thread would exit if no alarms are pending. To prevent this unintended exit all tasks are added to the scheduler's \textit{foreign\_tasks} list when they are scheduled on other threads. To end the program with other threads still running an explicit \textit{exit} op has to be issued.

\subsection{Garbage Collection (3)}

Since each interpreter has its own garbage collector and consequently its own memory areas and can only access its own data directly, the garbage collector can simply act as if there were no other threads. Thus the main work has been to clean up the interpreter structure itself and to replace references to global data by proxies. Only a few special cases had to be built into the GC itself. The global variable PMCNULL is used in many places in the code, but should be handled only by the main thread's garbage collector.

Before the implementation of threading support, having multiple interpreter objects in the system was used to implement things like a safe compartment where code can be run in a restricted environment. For such cases it was useful to share the garbage collector between interpreters. This special handling had to be removed.

Only the main thread is allowed to load additional bytecode or create new classes since it owns the data structures used to manage these things. Child threads use these via proxies. In previous implementation attempts code segments, classes and vtables have been copied for each new interpreter making thread startup a very costly operation while still causing subtle problems.

Code segments and vtables are only marked by the main thread's garbage collector. Code segments are managed in Parrot using \textit{PackFile} structures. Besides the code itself these structures contain tables of constants used in the code. These constants are expanded to PMCs by the bytecode loader when the code is loaded from disk or put there directly by the PIR compiler. Since \textit{PackFiles} are no PMCs, the Proxy PMC cannot be used to shield them from the GC. Accessing the contained constants would therefore lead to unproxied PMCs being accessed by different threads. Since PackFiles may only be loaded by the main thread anyway, the bytecode loader and the compiler were changed to flag all \textit{PackFile} constants as \textit{shared}. They still are used as is on all threads, but the GC knows to only handle \textit{shared} PMCs on the main thread.

Scheduling tasks on other interpreters may cause garbage collection due to the need of creating proxy objects. To protect the garbage collector from concurrency issues, garbage collection is disabled during creation of the new \textit{Task} object and the proxies on the target thread's \textit{interp}. But since the target thread may itself be allocating memory or collecting garbage, the GC has to be protected by a lock as well. The \textit{interp->thread\_data->interp\_lock} lock is used for this. It is checked by all allocation and freeing functions which are also the only places where a garbage collection run may be triggered.

\chapter{Tests and Benchmarks (4)}

In addition to Parrot's extensive test suite, tests were conducted using three test programs.

\section{tasks.pir}

tasks.pir is a simple test program, executing two \textit{Tasks} called ``a'' and ``b'' which run in tight loops printing their name on each 100000th iteration. The program ends after running for 10 seconds. This is a test of thread creation and task scheduling but does not access any shared data. The full code is as follows:
%
\begin{GenericCode}
.sub main :main
    .local pmc task, a, b, a_task, b_task
    task = get_global 'task'
    a = new ['String']
    a = "a"
    b = new ['String']
    b = "b"
    a_task = new ['Task']
    setattribute a_task, 'code', task
    setattribute a_task, 'data', a
    b_task = new ['Task']
    setattribute b_task, 'code', task
    setattribute b_task, 'data', b
    schedule a_task
    schedule b_task
    sleep 10
    exit 0
.end

.sub task
    .param pmc name
    .local int i
start:
    print name
    i = 0
loop:
    inc i
    if i >= 100000 goto start
    goto loop
.end
\end{GenericCode}

\section{moretasks.pir}

moretasks.pir is an extended test where the main task creates 50000 child tasks. These tasks would poll a shared variable with pauses of 100ms. When the variable is set to 1, they schedule tasks on the main thread to write their number to a results array. When the results array contains the expected number of results the process is repeated. This test stresses reading and writing to shared data, allocation and garbage collection. This test proved to be valuable for finding all sorts of concurrency issues. The complete source code is available in appendix \ref{app:moretasks}.

\section{matrix\_part.winxed}

This test implements multiplication of a matrix by a vector using four threads. It is written in the \textit{Winxed} programming language. Winxed is a low level language with JavaScript like syntax and the possibility to include sections of PIR code verbatim making it possible to try experimental opcodes while writing more readable and concise code than with PIR alone. The complete source code is available in appendix \ref{app:matrix_part}.

\section{chameneos.pir}

Chameneos is a game useful for testing peer-to-peer cooperation of threads presented in \cite{Chameneos}. The complete source code is available in appendix \ref{app:chameneos_part}.

\chapter{Conclusion, Further Work and Experiences (3)}

\begin{itemize}
\item Windows implementation for timer/alarm handling
\item Replace thread\_data->interp\_lock usage by preallocated proxy objects
\item Allow threads to create threads
\item Allow multi level proxying (don't create a proxy for a proxy, unpack first)
\item Allow redistribution of tasks to other threads
\end{itemize}

There are several places with an implicit assumption that new threads may be only started from the main thread. Similarly only the main thread may schedule tasks on other threads. Sub threads may schedule tasks only on the main thread, not on other sub threads. These restrictions are not inherent in the implemented threading model but were introduced due to time constraints.

\appendix
\chapter{moretasks.pir}
\label{app:moretasks}

\begin{GenericCode}
.sub main :main
    .local pmc task, sayer, starter, number, interp, tasks, results
    .local int i, num_results, results_rem
    interp = getinterp
    sayer = get_global 'sayer'
init:
    starter = new ['Integer']
    i = 1
    starter = 0
    say "1..100"
    tasks = new ['ResizablePMCArray']
    results = new ['ResizablePMCArray']
start:
    number = new ['String']
    number = i
    task = new ['Task']
    push task, results
    push task, starter
    setattribute task, 'code', sayer
    setattribute task, 'data', number
    print "ok "
    say number
    push tasks, task
    schedule task
    inc i
    if i > 50000 goto run
    goto start
run:
    starter = 1
check_results:
    pass
    num_results = results
    results_rem = num_results % 1000
    if results_rem != 0 goto skip_say
    say num_results
skip_say:
    if num_results >= 50000 goto end
    goto check_results
end:
    goto init
.end

.sub sayer
    .param pmc name
    .local pmc interp, task, starter, results, result_sub, result_task
    .local int i
    interp = getinterp
    task = interp.'current_task'()
    starter    = pop task
    results    = pop task
    result_sub = get_global 'push_result'
start:
    if starter > 0 goto run
    sleep 0.1
    goto start
run:
    result_task = new ['Task']
    setattribute result_task, 'code', result_sub
    setattribute result_task, 'data', results
    push result_task, name
    interp.'schedule_proxied'(result_task, results)
.end

.sub push_result
    .param pmc results
    .local pmc interp, task, number
    interp = getinterp
    task = interp.'current_task'()
    number = pop task
    push results, number
.end
\end{GenericCode}

\chapter{matrix\_part.winxed}
\label{app:matrix_part}

\lstinputlisting{/home/nine/install/parrot/examples/threads/matrix_part.winxed}

\chapter{chameneos.pir}
\label{app:chameneos_part}

\lstinputlisting{/home/nine/install/parrot/examples/threads/chameneos.pir}

\MakeBibliography{References, Literature (1)}

\include{messbox}
\end{document}
