\documentclass[bachelor,english]{hgbthesis}

\begin{document}

\title{Hybrid Threads for the Parrot Virtual Machine}

\author{Stefan Seifert}
\studiengang{Software Engineering}
\studienort{Hagenberg}
\abgabemonat{Februar}
\abgabejahr{2012}

\nummer{1010307037-A}
\gegenstand{SWE}
\semester{Wintersemester 2012}
\betreuer{Dr. Heinz Dobler}

\frontmatter
\maketitle
\tableofcontents

\chapter{Thanks (1)}

Andrew "whiteknight" Whitworth for laying the foundations for my work, being of tremendous help at all stages of the project and for fixing some of my bugs.

Nat "Chandon" Tuck for implementing green thread basics on which my work is based.

Christoph "cotto" Otto for bringing me into the Parrot project.

Brian "benabik" Gernhardt for lurking in the IRC channel and at least trying to help with my many questions.

\chapter{Abstract (1)}

\begin{german}
\chapter{Kurzfassung (1)}
\end{german}

\chapter{Table of Contents (1)}

	Perl 6 Concurrency
	About Parrot
	Parrot threads
	Nat "Chandon" Tuck green\_threads

\mainmatter

\chapter{Introduction and Motivation (3)}

On July 19th 2000, the Perl 6 design process was announced. Perl 5 had been a very flexible and widely used programming language but had started to show it's age and suffered from early design decisions. The Perl interpreter is written in C and has accumulated a lot of cruft over the years. The general consensus among the core developers was that the code had reached a state where maintenance was approaching impossibility. [http://use.perl.org/~masak/journal/40451]. An attempt to reimplement these internals had failed but led to the decision that the interpreter for a Perl 6 language should be developed independently of the needs of Perl 5. Since the Perl 6 syntax was very much in flux (and parts of it still are) the designers of these new internals tried to work very independently of any syntax related questions. [http://www.developer.com/lang/perl/article.php/10940\_3076571\_3/Perl-6-and-the-Parrot-Project.htm]. Taking up the name born in an April Fool's Day joke announcing the mergin of the Perl and Python programming languages, these new internals were called Parrot. [http://www.perl.com/pub/2001/04/01/parrot.htm]

Parrot evolved from being just the interpreter for the new version of Perl to being a language independent virtual machine providing features like garbage collection, exception handling and dynamic typing. At the time when the Parrot project started, the Java and .NET virtual machines were widely used, but both targeted statically typed languages. Parrot thus filled a quickly growing niche.

The Perl 6 design process began with asking the Perl users for what they were expecting from the new version of the language. The very first feature that got asked for was well integrated multi-threading support [http://dev.perl.org/perl6/rfc/1.html]. Perl 5 had two different implementations of thread support. In the first model, called 5005threads, data was shared by default and shared access to data had to be explicitely synchronized. This was similiar to the models used by languages such as C or Java. The implementation however suffered from data corruption and crashes and thus was not recommended for production use [http://search.cpan.org/~nwclark/perl-5.8.8/lib/Thread.pm]. Perl 5.6 introduced the newer model called ithreads, mostly as a way to emulate fork() on Win32 platforms. Perl 5.8 exposed this API to the user of the programming language. In this new model, all data would is copied to each thread and afterwards thread local. Data must be explicitely shared between threads. In other words, in Perl threads are not lightweight at all. They have severe impact on memory usage, writes to shared data are expensive and still not all features of the language are usable in threaded programs.

Being born at a time when Perl 6 still looked much more similiar to Perl 5 than it does nowadays, Parrot's threading support initially was very close to Perl's ithreads model. Previous attempts to change this into the more conventional model of data shared by default or implementing new technologies like Software Transactional Memory failed. For example Parrot has never supported running multiple threads and having garbage collection at the same time.

\section{Why is multi-threading support so important?}

In the year 2005 development of faster CPUs shifted from increased speed of a single core to adding more cores. Modern processors contain up to 12 cores with even mobile phones having up to four. To utilize a modern CPU's power, code needs to be run in parallel. In UNIX (and thus Perl) tradition, this is accomplished using multiple processes which indeed is a good solution for many use cases. For many others like Perl 6's auto threading of hyper operators, the cost of process setup and communication would be prohibitively high except for very large data sets.

\section{Why is it so difficult to implement multi-threading support in Perl or Parrot?}

Low level programming languages like C provide only the bare necessities, leaving the responsibility for preventing data corruption entirely to the user. A high level language like Perl 6 on the other hand offers complex and compund data types, handles garbage collection and a very dynamic object system. Even seeminlgy simple things like a method call can become very complex sequences. In a statically typed programming language the definition of a class is immutable. Thus calling a method on an object contains just the steps of determining the object's class, fetching the required method from this class and calling it. Calling the same method again may then even omit the first two steps since their results cannot change.

In a dynamic language, the object may change it's class at runtime. The inheritance hierarchy of the class may be changed by adding or removing parent classes. Methods may be added to or removed from classes (or objects) at runtime and even the way to find a method of a class may change. So a simple method call may result in the following steps:
%
\begin{itemize}
\item determining the class of the object
\item determining the method resolution method of the class
\item finding the actual method to call
\item calling the method
\end{itemize}
%
These steps have to be repeated for every following method call, because their results may change any time. In a threaded environment, a thread running in parallel may change the underlying data and meta data in between those sequences and even between those steps. As a consequence, this meta data has to be protected from corruption introducing the need for many locks in a very performance critical area.

While there are multi threaded garbage collection schemes, their implementation has not yet been attempted in Parrot.

Many interpreters for dynamic languages like Python or Ruby handle this problem by using a global interpreter lock to effectively serialize all operations. This is a proven and reliable way but again leaves much of the hardware's potential unused.

\section{Current status}

During these years of back and forth and failed attempts of adding threading support to Parrot, the Perl 6 specification evolved to a point where the largest parts of the language were covered and its features implemented in the compilers. The lack of concurrency primitives in Parrot prevents however prevents any progress in the area of concurrency support.

Currently Parrot does not have any threading support at all. The previous, defunct implementation has been removed.

This paper suggests a new approach based on a hybrid threading system. So called green threads are used to simplify the implementation of a nearly lock free multi threading implementation. This approach is based on a design by Andrew Whitworth and Nat Tuck.

\chapter{Concurrency in other Programming Platforms (5)}

\section{Java}
\section{Python}
\section{Erlang}

\chapter{Parrot (4)}

Parrot consists of the virtual machine (also called interpreter), and various tools to facilitate the implementation of programming languages on top of the Parrot VM (the Parrot Compiler Toolkit). In this paper, we concentrate on the virtual machine itself. The interpreter itself is written in C. Example code and testcases are written in PIR (Parrot Intermediate Representation) a high level assembly language which abstracts away register allocations and function calling conventions.

Contrary to other widely used virtual machines like the JVM or the CLR which are stack based, Parrot mirrors contemporary hardware CPUs more closely by being register based. The rationale behind giving up the simplicity of a stack based implementation is the hope of simplifying just in time compilation and improved performance of nested function and method calls.

The current design uses four sets of registers with each and unlimited number of usable registers. The four sets are:
%
\begin{itemize}
\item integer
\item floating point
\item string
\item polymorphic container (PMC)
\end{itemize}

The first three should be self explanatory. Strings in Parrot are a low level type with the interpreter handling all memory allocation issues and Unicode encoding. String values themselves are immutable.

\section{PMCs}

PMCs are containers for all higher level types such as objects, arrays, hash tables or code. Thus they are very similar to Python's PythonObject types. PMCs are defined by C structs and are fully garbage collected. Their definition looks like:
\begin{CCode}
struct PMC {
    Parrot_UInt    flags;
    VTABLE         *vtable;             /* Pointer to vtable. */
    DPOINTER       *data;               /* Pointer to attribute structure. */
    PMC            *_metadata;          /* Pointer to metadata PMC. */
};
\end{CCode}
In short it contains a pointer to a type specific data structure and some meta data. The vtable is where the type's behaviour is defined. It contains a long list of function pointers forming Parrot's unified type interface. This interface is a union of numeric, string, array, hash and object like behaviours. For example the  \textit{get\_integer} function returns an integer value for the data type. For a simple \textit{int} it's the contained value. For an array it may be the number of elements. The \textit{find\_method} function makes user defined methods of objects possible.

In this way, a language implementor can define the basic types of the language and available operations on them. For each vtable entry, there is a corresponding op code in Parrot's bytecode. Thus an \textit{inc \$P0} instruction is calling the \textit{increment} vtable function of the PMC contained in the \textit{\$P0} register.

\section{ParrotInterpreter}

The interpreter itself is represented by a C struct called \textit{parrot\_interp\_t}. This structure contains pointers to the garbage collector's runtime data, the loaded types, vtables, the runloop, the current continuation and other global data. A pointer to this structure is passed to almost every function as the first parameter.

\section{Continuation passing}

Control flow is modeled in Parrot using continuation passing. A continuation is a data structure containing the a state of a program at a given point in it's execution. It contains all information which is needed to continue a program in a certain state, e.g. a call stack, the instruction pointer and contents of local variables. ``Calling'' a continuation means restoring the state encapsulated in the continuation.

When a function is called, instead of pushing all this information on the stack, the function is given a return continuation as part of it's parameters. Returning from a function means calling the return continuation with possible return values stored in the registers where the calling code is expecting them. Continuation passing makes things like tail call optimization \footnote{When as the last statement of a function another function is called and it's value returned unchanged, the outer function may just pass on it's return continuation thus saving the need to create a new continuation and one step on returning from the nested function} very simple and as we will see later will be a very important piece in implementing green threads.

\section{Runloops}

A runloop is in principle the most inner loop executing bytecode in Parrot. It is also a data structure containing some information needed to support exception handling. When some operation in Parrot bytecode is calling a C function and this C function in turn is again executing Parrot bytecode, a nested runloop is started. Examples for such situations include calling a library function with a callback as parameter and exceptions thrown inside Parrot's C code which call a previously defined exception handler in user code.

\section{Exception handling}

Before entering a runloop, the \textit{setjmp} C function is used to save the current stack position and register contents to a data structure stored in the runloop meta data. This is effectively creating something resembling a continuation at C level. When an exception is created within the interpreter, the runloop stack is searched for the runloop containing a suitable exception handler. \textit{longjmp} is then used to unwind the call stack up to the point where setjmp was called and the call environment restored. While having great similarities with continuations, this mechanism is more limited. It only allows to jump back to a point higher in the call stack.

\section{Garbage collector}

Parrot supports different garbage collector implementations which can be selected at interpreter startup. Currently there are four existing implementations of different algorithms:
\begin{itemize}
\item Inf: a GC for debugging purposes which never collects any garbage
\item MS: a basic mark and sweep implementation
\item MS2: a non-recursive mark and sweep implementation
\item GMS: a generational, non-compacting, mark and sweep GC
\end{itemize}
with GMS being the default.

A mark and sweep garbage collector operates in two phases. In the mark phase, starting from a known root set of objects, the GC follows pointers down the object tree, marking each encountered object as alive. In the sweep phase, all objects which are not alive are destroyed and the live flags reset.

In a process with many objects, having to traverse the whole tree may take a considerable amount of time. To mitigate this, a generational garbage collector extends this algorithm by assuming that the longer an object has lived, the lower the chances are that it will become unused. So the objects are partitioned into different generations. The youngest generation would always be traversed while the older generations would be handled much less frequently or even never more at all.

\section{Historical development (1)}

\chapter{Green threads (3)}

There are three possible ways how two subroutines could be (at least seemingly) run in parallel:
\begin{itemize}
\item Coroutines
\item Green threads 
\item Operating system threads
\end{itemize}

\section{Coroutines}

Coroutines are functions which retain their state between calls. Instead of returning, they yield control back to the calling function, possibly with an intermediate result returned. A very simple example in Python could look like:
\begin{GenericCode}
def counter():
    for i in range(0, 100):
	yield i
\end{GenericCode}
This function would return one integer for every call, counting from 0 to 100. For two functions to run in parallel, they have to cooperate. One by calling the other repeatedly and the callee by yielding control back to the caller.

\section{Operating system threads}

Operating system threads are like multiple processes running at the same time but share their memory. The operating system is responsible for giving each of these threads CPU time to run.

\section {Green threads}

"Green threads" or "lightweight threads" are threads which are managed by the virtual machine instead of by the operating system. The virtual machine contains a scheduler and support for preempting running tasks.
Preemption means to suspend a task regardless of what it's currently doing and probably resuming it later on.
This is an implementation of the many-to-one threading model very similiar to what an operating system running on a system with a single CPU core does.
%
Advantages of green threads are:
%
\begin{itemize}
\item They allow pseudo concurrent processing without endangering the interpreter's internal consistency.
\item Green threads are very light weight with low memory overhead and close to zero creation time.
\item They do not depend on OS threading support
\item The interpreter controls the point at which a green thread is preempted.
\item The interpreter controls the exact scheduling policy and may allow the user to influence it or even take over completely.
\item Garbage collection can be implemented like in a single threaded process.
\item Critical sections may simply be protected by disabling the scheduler.
\end{itemize}
%
Disadvantages include:
%
\begin{itemize}
\item They do not allow more than one CPU core to be used for computations.
\item Blocking calls like I/O block the whole interpreter including other green threads.
\item The interpreter has to contain logic and timers to control green threads.
\end{itemize}

Green threads differ from coroutines in that the interpreter decides when a running task is to be preempted while a coroutine depends on manual yield calls.

Let's look at a simple example to explain why concurrent processing could endanger the interpreter's internal consistency. The basic problem is concurrent writes to shared data. Assume we have an implementation of an array class consisting of the field holding the data and the number of contained elements in a seperate member variable:
\begin{CCode}
pmclass ResizableIntegerArray auto_attrs provides array {
    ATTR INTVAL   size;      /* number of INTVALs stored in this array */
    ATTR INTVAL * int_array; /* INTVALs are stored here */
\end{CCode}
To append a new value, the array would have to read the current size, write the new value at the position size + 1 and then write the incremented size back into the member variable.
Now if two threads simultainously try to do this, it may happen that both read the same size, write to the same position (with one overwriting the value of the other) and write back the same incremented size. In this case one of the appended values would be lost.

In a more complicated example, the array could have to resize it's data buffer to accomodate the new value. It would read the current size, allocate a new buffer, copy the values to the new buffer and then destroying the old one. Again if two threads try to do this simultainously, one of them could still be copying data, while the other is already at the point where it destroys the old buffer. This would lead to the copying thread accessing freed memory.

\section{Green threads in Parrot}

Parrot's green threads implementation is based on Nat Tuck's green\_threads branch developed during his Google Summer of Code internship.

In Parrot green threads are called \textit{Task}. Each task is assigned a fixed amount of execution time. On expiry a timer callback sets a flag which is checked for at execution of every branch operation. Since the interpreter's state is well defined at this point, it's internal consistency is guaranteed. The same goes for the garbage collector. Since task preemption is only done while executing user level code, the GC can do it's work undisturbed and without the need for measures like locking. Since user level code is allowed to disable the scheduler, it can be guaranteed to run undisturbed through critical sections.

The scheduler is implemented as a PMC (Parrot's polymorphic container type). The plan is to allow the user to subclass this PMC thus allowing very fine grained control over the scheduling policy.

\chapter{Design of Hybrid Threads (3)}

Using green threads we're now solving the following problems which occur when trying to implement threading support:
%
\begin{itemize}
\item How to ensure internal interpreter consistency when doing writes to shared data.
\item How to handle garbage collection.
\end{itemize}

\section{Shared data}


\section{Garbage Collection}

\chapter{Implementation of Hybrid Threads (15)}

\section{Runloops (1)}

\section{The Scheduler (4)}

\section{Threads (5)}

\subsection{Creation (1)}

\subsection{Proxies (2)}

\subsection{Writing shared data (2)}

\subsection{Garbage Collection (3)}

\chapter{Tests and Benchmarks (4)}

\chapter{Conclusion, Further Work and Experiences (3)}

\begin{itemize}
\item replace thread\_data->interp\_lock usage by preallocated proxy objects
\item allow threads to create threads
\item allow multi level proxying (don't create a proxy for a proxy, unpack first)
\end{itemize}

\MakeBibliography{References, Literature (1)}

\include{messbox}
\end{document}
