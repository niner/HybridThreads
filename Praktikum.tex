\documentclass[praktikum,german]{hgbthesis}
\graphicspath{{images/}}   				% wo liegen die EPS-Bilder?
%\AddBibFile{literatur.bib}  % Angabe der BibTeX-Datei


%%%----------------------------------------------------------
\begin{document}
%%%----------------------------------------------------------

\author{Stefan Seifert}
\studiengang{Software Engineering}
\studienort{Hagenberg}
\abgabemonat{Februar}
\abgabejahr{2012}

\nummer{1010307037-B}
\betreuer{Mag. Thomas Seel}
\firma{%
   Atikon EDV \& Marketing GmbH\\
   4020 Leonding, Kornstraße 4
}
\firmenTel{+43 732 611266}
\firmenUrl{www.atikon.com}

%%%----------------------------------------------------------
\frontmatter
\maketitle
\tableofcontents
%%%----------------------------------------------------------

\chapter{Kurzfassung}

Atikon EDV \& Marketing GmbH entwickelt Webseiten hauptsächlich für Steuerberater und Ärzte, sowie Software für Steuerberater. Als Leiter der Webprogrammierung führe ich ein Team von 5 Programmierern. Wir entwickeln Software für den internen Gebrauch sowie für externe Kunden, z.B. das Content Management System, die Projektverwaltung, Online-Steuerberech\-nung und Individualentwicklung wie z.B. ein CRM System für einen unserer Kunden.

Mit inzwischen über 1100 aktiven Webseiten ergeben sich in der Programmierung interessante Aufgaben von der Skalierung des Systems über die User Interface Gestaltung bis zur Automatisierung von Routineaufgaben um die Wartung und Pflege der Webseiten so effizient wie möglich zu gestalten.

Bei der Programmierung des Content Management Systems galt es ein bestehendes System abzulösen, das mit fast 1000 Webseiten an seine Grenzen gestoßen war. Ziel war dabei eine vollständige Übernahme von bestehenden Webseiten in das neue System, da diese weiterhin gewartet werden müssen und automatisiert Inhalte wie Steuernews darauf verteilt werden. Während das alte CMS auf Python basiert und eine objektorientierte Datenbank (ZODB) benutzt, ist das neue in Perl geschrieben und benutzt \textit{PostgreSQL} als Datenbank.

Meine Aufgaben waren dabei neben der Projektleitung:
%
\begin{itemize}
\item{Entwurf der Architektur des neuen Systems}
\item{Implementierung der Grundstruktur}
\item{Implementierung des Exports aus dem alten CMS}
\item{Implementierung der Unterstützung für die Templatesprache des alten CMS}
\item{Erweiterung des Inline::Python Perlmoduls um die von uns benötigten Features}
\item{Implementierung von automatischen Kompatibilitätstests mittels Vergleich von Screenshots der Webseiten mit allen Unterseiten.}
\end{itemize}

%%%----------------------------------------------------------
\mainmatter           %Hauptteil (ab hier arab. Seitenzahlen)
%%%----------------------------------------------------------

\chapter{Das Unternehmen}
Atikon EDV \& Marketing GmbH mit Sitz in Leonding bietet in den 11 Jahren ihres Bestehens mit 55 Mitarbeitern Marketingdienste für Steuerberater und Ärzte und entwickelt Beratungssoftware für Steuerberater. Diese Spezialisierung spiegelt sich in der Kundenstruktur wieder. Unter den ca. 3400 Kunden befinden sich in etwa 80 \% Steuerberater, 10 \% Ärzte und 10 \% sonstige Unternehmer.

Diesen Kunden werden im Marketingbereich Websites mit individuellem Design und verschiedenste Drucksorten angeboten. Dazwischen gibt es noch Hybridprodukte wie Steuernews und Steuerinfo, welche in die Webseite eingebunden oder gedruckt verteilt werden können. Abgerundet wird das Portfolio durch Onlinetools wie Steuerrechner, z.B. zur Brutto/Netto Berechnung oder zur Einkommensteuerberechnung und einem Newslettersystem.

Die Beratungssoftware wird vom Team der Windowsprogrammierung erstellt. Hier gibt es eigenvertriebene Produkte wie die "Formel-f" oder Software zur Bilanzpräsentation und Auftragsarbeiten, z.B. für die deutsche DATEV.

Das fünfköpfige Team der Webprogrammierung kümmert sich um Webanwendungen sowohl für den internen Gebrauch, als auch für externe Kunden. Dazu gehören:
%
\begin{itemize}
\item das Content Management System
\item Projektverwaltung
\item Onlinetools (z.B. die Steuerrechner)
\item Newslettersystem
\item Kundenprojekte wie z.B. ein Online-CRM-System
\end{itemize}

Die Software ist dabei größtenteils in Perl geschrieben. Als Datenbank kommt hauptsächlich \textit{PostgreSQL} zum Einsatz. Alte Anwendungen sind teilweise in PHP oder Python geschrieben und setzen auf MySQL.

\chapter{Projekt CMS 3000}

\section{Einleitung}

Websites sind eines der Hauptprodukte der Firma. Die Kundenstruktur findet sich auch abgebildet auf die ca. 1600 bisher erstellten Websites wieder. Steuerberater sind zumeist eher kleine Unternehmen. Es gibt jedoch unter ihnen auch Netzwerke aus zahlreichen Einzelunternehmen mit zusammen 100en Standorten und 1000en Mitarbeitern. Dementsprechend sind auch bis auf einzelne Ausnahmen die meisten der von uns erstellten und betreuten Websites relativ klein. Die wichtigsten Verkaufsargumente sind die einerseits verfügbaren branchenspezifischen Inhalte wie z.B. regelmäßig aktualisierte Steuernews, andererseits aber die vollständige Individualisierung von Layouts und Websitestruktur.

\section{Projektziel}

Das Projekt, das in dieser Arbeit beschrieben wird, hatte zum Ziel, das bestehende Content Management System, welches durch das Wachstum des Kundenstammes an seine Grenzen geraten war, durch ein neu entwickeltes abzulösen. Ziele waren dabei, die Verbesserung von Peformance, Zuverlässigkeit und Usability sowie das Schaffen von mehr Anpassungsmöglichkeiten an unsere Anforderungen.

\section{Das abzulösende System}

In den ersten 10 Jahren des Firmenbestehens wurde das deutsche Produkt \textit{ZMS} eingesetzt. Es handelt sich dabei um freie, GPL lizenzierte Software, die in Python geschrieben ist und auf dem \text{Zope} Application Server basiert. \textit{Zope} bringt eine eigene, objektorientierte Datenbank mit, genannt ``ZODB''. Diese Datenbank ist im Prinzip ein serialisierter Graph von Pythonobjekten, der zusammen mit den Indizes in einer Datei gespeichert wird. Der Application Server bringt eine eigene Weboberfläche mit, in der diese Datenbank als hierarchische Ordner- und Dateistruktur dargestellt wird.

\textit{ZMS} führt diese Grundstruktur fort, indem es die Inhalte von Webseiten ebenfalls in einer Ordner- und Dokumentenstruktur präsentiert. Das Layout wird durch Templates definiert, die in der \textit{Zope}-eigenen Templatesprache \textit{DTML} geschrieben sind. Diese Sprache bietet in einer HTML-ähnlichen Syntax die üblichen Konstrukte wie Verzweigungen, Schleifen, Definition und Ausgabe von Variablen. Diese Konstrukte unterstützen dabei die Formulierung von komplexen Ausdrücken in Python:
%
\begin{GenericCode}
    <dtml-var "getObjProperty('foo', REQUEST).upper()" html_quote>
\end{GenericCode}

In diesem Beispiel wird die \textit{getObjProperty} Methode des Kontextobjekts aufgerufen mit dem String ``foo'' und dem immer verfügbaren REQUEST-Objekt als Parameter. Als Ergebnis wird ein String erwartet, dessen upper() Methode den String in Großbuchstaben zurückliefert. Das Ergebnis des Ausdrucks wird ausgegeben, wobei Zeichen, die in HTML eine spezielle Bedeutung haben escaped werden.

Das für uns wichtigste Feature des \textit{ZMS} war die einfache Erweiterbarkeit der zur Verfügung stehenden Inhaltsobjekte. \textit{ZMS} erlaubt die Definition von eigenen sogenannten ``speziellen Objekten'' mit beliebigen Datenfeldern und eigenem Ausgabetemplate. Das Eingabeinterface wird dabei automatisch generiert. Damit ist es z.B. sehr einfach möglich für eine Mitarbeiterseite ein Mitarbeiter-Objekt zu definieren wo der entsprechende Mitarbeiter mit Namen, Emailadresse und Durchwahl zusammen mit einem Bild ausgegeben wird. Dieser Mechanismus erlaubt es, unterschiedlichsten Kundenanforderungen gerecht zu werden.

\section{Probleme}

Die Probleme, die zum Entschluss einer Neuprogrammierung geführt haben, waren dabei folgende:

\subsection{Zuverlässigkeit}

Der \textit{Zope}-Server kann nur starten, wenn er die \textit{Zope}-Datenbank lesen kann. Gleichzeitig ist die Weboberfläche des \textit{Zope}-Servers die einzige Möglichkeit um die \textit{Zope}-Datenbank manuell zu bearbeiten. Ist nun die Datenbank durch Programmfehler beschädigt, gibt es kaum Mittel um sie zu reparieren. Derartige Probleme haben die Firma schon komplette Arbeitstage gekostet und dazu geführt, dass am Schluss ein stündliches Backup der Datenbank erstellt wurde.

\subsection{Performance}

Operationen, die alle Websites betreffen wie zum Beispiel das Update von gemeinsamen Inhalten, das bloße Auflisten aller Websites oder ein Durchsuchen aller Websites zeigten ein höchst unberechenbares und exponentielles Laufzeitverhalten. Das Auflisten der Websites konnte von wenigen Sekunden bis zu mehreren Minuten dauern. Das Inhaltsupdate lief mehrere Stunden während derer der Zugriff extrem verlangsamt wurde, weshalb es nur über Nacht durchgeführt werden konnte.

In \textit{Zope} wird jeder Webrequest automatisch in einer Transaktion ausgeführt. Treten Zugriffskonflikte mit anderen Transaktionen auf, wird die Transaktion automatisch zurückgesetzt und der Request wiederholt. Dies passiert vollautomatisch bis zu drei Mal bevor \textit{Zope} den Request mit einer Fehlermeldung beendet. Bei Transaktionen, die mehrere Stunden laufen ist die Chance auf ein erfolgreiches Durchkommen sehr klein und die Zeit bis zur erfolgreichen Erledigung sehr lang. Als Abhilfe wurden derartige Zugriffe möglichst unterteilt (z.B. das Inhaltsupdate nur für einzelne Websites) und von außen gesteuert durchgeführt. Dies hat die Komplexität und damit die Fehleranfälligkeit wieder erhöht.

Die Speicherung als Objektgraph macht bestimmte Operationen, die in SQL Datenbanken sehr schnell gehen äußerst langsam, z.B. das Durchsuchen der gesamten Website nach Objekten eines bestimmten Typs um zum Beispiel die neuesten News aller Kategorien gesammelt auf einer Startseite anzuzeigen.

\subsection{Wartbarkeit}

\textit{DTML} verleitet dazu Präsentation und Logik zu mischen und beides in einem Template einzubauen. Gleichzeitig macht es durch fortgeschrittene Features das Lesen von Code schwierig und unzuverlässig. Es gibt in \textit{DTML} nur einen einzigen, großen Namensraum. In diesem sind die Methoden und Eigenschaften des impliziten Kontextobjekts genauso enthalten, wie eingebaute Funktionen der Sprache und die aller höher liegenden Objekte in der Hierarchie. Da Templates und Scripte als Datei-Objekte üblicherweise im Wurzelverzeichnis einer Website abgelegt werden, sind diese als Eigenschaften des Wurzelverzeichnises überall ohne weitere Qualifikation verfügbar. Das trifft jedoch auch auf Objekte zu, die weiter oben in der Hierarchie liegen. Zum Beispiel hat das Anlegen eines Ordners namens ``test'' in der obersten Hierarchieebene dazu geführt, dass bei manchen Websites Fehler ausgegeben wurden, weil in manchen Ausdrücken dieser Ordner statt der globalen Funktion gleichen Namens gefunden wurde und ein Ordner kein ausführbares Objekt ist.

\section{Anforderungen}

Entsprechend der Kundenstruktur gestalten sich auch die Anforderungen an das Content Management System:
%
\begin{itemize}
\item Unterstützung für 1000e individuelle Websites in einem System
\item Einfache Verteilung und Updates von gemeinsam genutzten Inhalten
\item Völlige Freiheit bei Design und Struktur
\item Individuelle Erweiterungen
\item Einfache Bedienung für Kunden mit Eigenwartung
\end{itemize}

Die Entscheidung für eine Eigenentwicklung wurde aus zwei Gründen gefällt. Einerseits wurde bei einer Marktanalyse kein System mit einem ähnlich gut auf die Kundenstruktur passendem Featureprofil gefunden. Andererseits bestand der Wunsch für die bestehenden 1000 Websites einen Upgradepfad zu ermöglichen um den Wartungsaufwand zu minimieren.

\chapter{Umsetzung}

Der erste Prototyp wurde von mir geschrieben und der Geschäftsführung präsentiert. Vor allem war der direkte Performancevergleich zum Altsystem überzeugend, weshalb das Projekt genehmigt wurde und in die Entwicklung ging. Nach Erstellung des Grundsystems kam nach und nach der Rest des Teams zum Projekt dazu. Mit der Umstellung auf die Entwicklung im Team wurden auch eine Testsuite eingeführt.

\section{Grundstruktur}

Als Datenspeicher wurde \textit{PostgreSQL} gewählt, eine freie und zugleich mächtige und performante SQL Datenbank. Um die einfache Erweiterbarkeit des \textit{ZMS}, wo für jede Seite neue Objekttypen definiert weden können und sogar bestehende um neue Felder erweitert, zu erhalten, bekommt jede Website ein komplett eigenes Datenbankschema. Diese Schemata werden in der Datenbank als getrennte Namensräume (im \textit{PostgreSQL} Jargon ebenfalls ``schema'') ausgeführt. Da dadurch die Anzahl der Datenbanktabellen mit jeder Website stark steigt, wurden Voruntersuchungen durchgeführt, ob \textit{PostgreSQL} mit mehreren 100.000 Tabellen umgehen kann. Es wurden dabei keine inhärenten Einschränkungen gefunden. Die Skalierung hängt rein vom darunterliegenden Dateisystem ab. Das verwendete \textit{ext4} scheint gut zu skalieren.

Die Wahl der Programmiersprache fiel auf Perl, da in der Firma viel Know How für diese Sprache vorhanden ist. Mit \textit{Catalyst} steht ein flexibles MVC Framework für Webanwendungen zur Verfügung. Im \textit{Perl Comprehensive Archive Network} (\textit{CPAN}) sind unzählige Libraries verfügbar, von denen ca. 80 dann auch verwendet wurden. Weiters ausschlaggebend war die gute Unterstützung für UTF-8 codiertes Unicode.

Ein Risikofaktor bei dieser Wahl war die Unterstützung für 10.000e bestehende Templates und die Python-Ausdrücke, die diese enthalten. Mögliche Varianten waren hier eine automatisierte Übersetzung von Python auf Perl und das Einbinden eines Python-Interpreters mittels des Inline::Python Perlmoduls. Den Ausschlag für letzteres gab dessen Fortgeschrittenheit im Vergleich zu den bestehenden Übersetzungslösungen.

Die Anwendung wird vom Webserver über das FastCGI Protokoll angesprochen, da \textit{Catalyst} dafür alles nötige bereits mitbringt. \textit{memcached} wird als gemeinsamer Objektcache verwendet um die Datenbank zu entlasten.

\section{Datenbankaufbau}

Jede Website besitzt ein eigenes Datenbankschema, das in einem PostgreSQL-schema, benannt nach dem Domainnamen der Website, enthalten ist. Für jede Objektart gibt es hier eine eigene Tabelle. Alle Typen sind von einer gemeinsamen Basisklasse namens \textit{ZMS::Object} abgeleitet. Das spiegelt sich im Datenbankschema wieder. In einer Tabelle namens \textit{zms\_object} werden für jedes gespeicherte Objekt die Eigenschaften der Basisklasse gespeichert. Das sind neben der von der Datenbank vergebenen, Website-weit eindeutigen \textit{uid} und einer textuellen \textit{id}, die nur unter den Kindobjekten eines gemeinsamen Elternobjektes eindeutig sein muss, vor allem auch der Name der Tabelle, in der die typspezifischen Daten gespeichert sind. Weiters finden sich dort ein Verweis auf das Elternelement, Informationen zur Sortierreihenfolge, das \textit{active} Flag und Änderungsdaten. Für jeden Typ gibt es neben einer eigenen Tabelle auch eine writable View die die jeweilige Tabelle und \textit{zms\_object} zusammenführt.

Das Datenbankschema selbst ist in den Tabellen \textit{zms\_meta\_objects} und \textit{zms\_object\_attrs} beschrieben, wo es für jeden Typ bzw. jedes Attribut eines Typs Einträge gibt. Diese Tabellen werden zusammen mit \textit{zms\_languages}, welche Informationen über die in dieser Website verfügbaren Sprachen enthält, zu Beginn jedes Requests gelesen.

Die Objekte einer Website werden in einem Baum verwaltet. Um Abfragen auf Teilbäume effizienter zu machen, werden in der Tabelle \textit{zms\_object\_\-tree} Informationen über die Baumstruktur gespeichert. Sie erlaubt effiziente Abfragen auf komplette Unterbäume mit optionaler Begrenzung der Suchtiefe. Die Informationen werden von Triggern in der Datenbank automatisch bei Änderungen an den Daten aktualisiert.

Mehrsprachigkeit wird unterstützt indem bei mehrsprachigen Objekteigenschaften jeweils ein Datenbankfeld für jede Sprache angelegt wird. Ist ein Feld in einer Sekundärsprache NULL wird ein Fallback auf die für diese Sprache angegebene Vorgängersprache durchgeführt. Werden neue Sprachen hinzugefügt, oder bestehende entfernt müssen daher alle Datenbanktabellen und Views entsprechend angepasst werden.

\section{Klassenhierarchie}

\textit{ZMS::Object} ist die Basisklasse für alle vom CMS verwalteten Objekte und enthält den Großteil des Interfaces für Templatecode. \textit{ZMS::ContainerObject} ist davon abgeleitet und ist ihrerseits die Basisklasse für alle Objekte, die sich wie Ordner verhalten und Kindobjekte im Baum enthalten können. Von diesen beiden Klassen sind alle Klassen von Inhaltsobjekten abgeleitet. Vom Benutzer erstellte Objekttypen werden von \textit{ZMS::Custom} repräsentiert.

Die von den Inhaltsobjekten unterstützten Attribute sind als von \textit{ZMS::\-Attribute} abgeleitete Klassen implementiert. Sie enthalten Informationen über den möglicherweise benutzten Datentyp eines Datenbankfeldes, Code zum Rendern des Eingabeinterfaces und für die Eingabevalidierung.

\textit{Catalyst} gibt eine Grundstruktur für den Aufbau der Anwendung mit Unterteilung in Models, Views und Controllern vor. \textit{ZMS::Model::DB} implementiert alle low level Datenbankzugriffe und generiert daher auch alle verwendeten SQL Statements. Um die Ausgabe der Website kümmert sich \textit{ZMS::Controller::Content}. Die Verwaltung der Inhalte wird von \textit{ZMS::Con\-troller::Content::Management} gestellt. Die Verwaltung der Metadaten wie Typen, Sprachen und Benutzer finden sich im \textit{ZMS::Controller::System} Namensraum.

\section{DTML}

In \textit{ZMS::View::DTML} ist das Parsen und Ausführen von DTML Templates implementiert. DTML Anweisungen folgen ähnlich zu HTML immer dem Aufbau:
<dtml-\textit{command} \textit{options}... \textit{attribute}="\textit{value}"... \textit{options}...>. Sie sind dabei jedoch unabhängig von der HTML Struktur und können an beliebigen Stellen des HTML Codes vorkommen. Beim Parsen wird das Templates mit Hilfe einer Regular Expression in Chunks unterteilt und dabei gleichzeitig der DTML-Ausdruck selbst geparst. Daraus wird anschließend Perlcode generiert, der mit mittels eval Anweisung ausgeführt wird. Für jede DTML-Anweisung konnte eine Perl-Entsprechung gefunden werden.

Der generierte Perlcode wird in einem Cache-File zwischengespeichert. Benannt wird die Datei nach dem DTML Template: headCSS.dtml wird zu .headCSS.dtml.cache

\section{Inline::Python}

Inline::Python ist ein Perl-Modul, das einen Python-Interpreter in den Perl-Prozess einbindet. Diesen Interpreter kann man benutzen um im selben Prozess Python-Code auszuführen. Inline::Python kümmert sich dabei darum, die Daten von Perl nach Python bzw. umgekehrt zu übersetzen, sodass das Verwenden von Pythonfunktionen von Perlcode heraus und umgekehrt völlig transparent erscheint.

Das Modul wurde von Neil Watkiss entwickelt, der jedoch die Weiterentwicklung nach Version 0.22 vom Jänner 2005 aufgeben musste. Diese Version konnte bereits vieles von der benötigten Funktionalität, enthielt jedoch noch sehr viele Fehler im Speichermanagement. Ich habe daher die Weiterentwicklung offiziell übernommen und war seither für alle Releases (aktuell ist Version 0.40) verantwortlich. Die Fehler rührten daher, dass beide Programmiersprachen eine Reference Count basierende Garbage Collection benutzen, jedoch mit subtilen Unterschieden. Z.B. hält in Python der Stack eine implizite Referenz auf den Rückgabewert einer Funktion, während in Perl die Funktion dafür verantwortlich \textit{sv\_2mortal()} aufzurufen, womit der Referenzzähler nach dem Ausführen der nächsten Perl-Anweisung heruntergezählt wird. Abgesehen davon muss in beiden Sprachen die Referenzzählung in C Code manuell mittels Aufruf entsprechender Makros durchgeführt werden.

Diese Zählung war größtenteils falsch. Es wurde sowohl an den falschen Stellen hinauf- wie hinuntergezählt. Das hat dazu geführt, dass Inline::Python zwar oberflächlich funktioniert hat, aber viel Speicher verloren ging. Die Fehler haben sich teilweise gegenseitig aufgehoben, sodass beim Beheben eines Fehlers an einer Stelle dafür ein Fehler an einer anderen aufgetaucht ist. Beheben ließ sich das durch die Erweiterung der Testsuite um umfangreiche Reference Counting Tests und genaues Studium der Entwicklerdokumentation und des Quellcodes sowohl von Python als auch von Perl.

\section{Tests}

Vor der Übernahme der bestehenden Websites in das neue CMS wurden umfangreiche Tests durchgeführt. Diese liefen in drei Phasen ab:

\subsection{Manuelle Tests}

Zufällig ausgewählte Websites wurden manuell durchgeprüft, ob die Ausgabe mit der Originalversion übereinstimmt oder ob unerwartete Fehlermeldungen kommen. In der Anfangsphase wurde man hier noch schnell fündig. Nach Test und Debugging von ca. 10 Websites war die Fundquote jedoch zu niedrig um den Aufwand zu rechtfertigen.

\subsection{Tests auf Fehlermeldungen}

In der nächsten Phase wurden alle 1500 Websites ins neue System importiert und mittels eines Webcrawlers nach Fehlermeldungen des CMS durchsucht. Auf diese Art wurden ca. 100 kleinere Inkompatibilitäten gefunden und behoben.

\subsection{Screenshotvergleiche}

Nachdem keine Fehlermeldungen mehr übrig waren wurde der Crawler erweitert, sodass er durch Fernsteuerung eines Browsers automatisiert Screenshots jeder einzelnen Seite jeder einzelnen Website angefertigt hat und mit einem entsprechenden Screenshot der Originalseite verglichen hat. Waren die Bilder nicht pixelweise identisch wurde dann ein Differenzbild der Screenshots erzeugt. Diese Differenzbilder wurden dann manuell durchkontrolliert und dabei gefundene Fehler behoben.

\chapter{Ergebnis}

\begin{figure}
\includegraphics[width=1\textwidth]{curl_atikon}
\caption{Durchschnittliche Antwortzeit von www.atikon.com vor und nach der Migration in Sekunden.}
\label{fig:atikon}
\end{figure}

\begin{figure}
\includegraphics[width=1\textwidth]{curl_lask}
\caption{Durchschnittliche Antwortzeit von www.lask.at vor und nach der Migration in Sekunden.}
\label{fig:lask}
\end{figure}

Bereits vor den umfangreichen Kompatibilitätstests wurde angefangen, neue Websites nur noch mit dem neuen CMS zu entwickeln. Damit konnten einerseits noch Fehler in der Benutzeroberfläche gefunden werden und andererseits weiterer Umstellungsaufwand vermieden werden. Die Umstellung der bestehenden Websites wurde dann nach Abschluss der Tests schubweise durchgeführt. Wie in Abbildung \ref{fig:atikon} und \ref{fig:lask} zu sehen ist, verbesserten sich die Antwortzeiten der umgestellten Websites teilweise erheblich. Durch die einfachere Parallelisierbarkeit sind jetzt auch Besucherabstürme auf der Homepage des LASK kein Problem mehr für den Server. Beschwerden über die Performance sind völlig verschwunden.

PostgreSQL hat sich als sehr stabile Basis erwiesen. Von Beginn des Projektes an lief es zuverlässig und problemlos. War früher ein Update der verteilten Inhalte ein fragiler und langwieriger Prozess, der nur außerhalb der Geschäftszeiten durchgeführt werden konnte, wird es jetzt jederzeit bei Bedarf durchgeführt, da es keinen spür- oder messbaren Einfluss auf die Performance des Systems hat.

Durch den performanten Zugriff auf die SQL Datenbank wurden neue Auswertungen ermöglicht. Abfragen, welche Websites welche Inhalte oder Onlinerechner eingebunden haben lassen sich jetzt innerhalb von Sekunden beantworten.

Das Projekt kann daher als voller Erfolg bezeichnet werden.

\chapter{Erfahrungen und Zusammenfassung}

Das Projekt war in vielerlei Hinsicht sehr lehrreich. Auf technischer Seite waren vor allem das Ausreizen der Datenbank zur Speicherung hierarchischer Objektgraphen und die Weiterentwicklung von Inline::Python herausfordernd. Letzteres war für mich der erste Kontakt sowohl mit den Interna von Perl wie auch derer von Python. Es war für mich außerdem das erste Projekt bei dem eine mehrschichtige Cachinginfrastruktur zum Einsatz kam. Der Wert einer umfangreichen und gut strukturierten Testsuite hat sich im Laufe des Projektes mehrfach gezeigt und die Erfahrungen damit sind bereits ins nächste Projekt eingeflossen.

Organisatorisch war es Neuland, ein Projekt dieser Größe neben dem Tagesgeschäft als noch sehr junges Team durchzuführen. Zwei der Teammitglieder waren am Anfang noch nicht mal mit Perl vertraut. Einen Termindruck von Auftraggeberseite gab es zwar nicht, aber je länger die Entwicklungs- und Umstellungsphase dauerte, desto mehr Websites galt es zu migrieren. Die Umsetzer entdeckten in dieser Zeit außerdem viele neue Features des Altsystems, die dann wiederum nachgebaut werden mussten.

Während des Projekts wurde von Subversion auf git als Sourcecodeverwaltung migriert. Der Aufwand, sich in das neue System einzulernen wurde jedoch von der besseren Unterstützung bei der Entwicklung mehr als aufgewogen.

Trotz massiver Verbesserung bei Performance und Usability im Vergleich zum abgelösten System lief die Einführung nicht ohne Widerstand von Benutzerseite. Dieser begründete sich vor allem auf die nötige Umgewöhnung sowie auf Verunsicherung über die Zukunft der Software, da sie nicht als das Ergebnis eines Teamprojekts wahrgenommen wurde, sondern als meine persönliche Schöpfung. Mit etwas Überzeugungsarbeit ließen sich diese Hürden jedoch überspringen.

Abschließend sei die Weitsicht der Unternehmensführung hervorzuheben, die das Risiko einer derartigen Eigenentwicklung eingegangen ist. Dem Aufwand stand die zentrale strategische Bedeutung für das weitere Wachstum der Firma gegenüber. Die Chance solche Projekte durchführen zu können macht Atikon zu einem derart schönen Arbeitsplatz.

%%%----------------------------------------------------------
% Quellenverzeichnis (sofern notwendig, sonst weglassen)
%\MakeBibliography{Quellenverzeichnis}

%%%Messbox zur Druckkontrolle
%\input{messbox.tex}

\end{document}

% vim: spell spelllang=de_at
